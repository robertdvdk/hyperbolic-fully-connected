# W&B Sweep configuration for genome hyperbolic experiments
# Usage: wandb sweep sweep_config.yaml
#
# This sweep trains on ALL TEB datasets and optimizes the aggregate MCC.
# The aggregate metric is the average normalized MCC across datasets.

program: main.py
method: random  # Use Bayesian optimization for continuous parameters
metric:
  name: aggregate/mean_mcc
  goal: maximize

parameters:
  # Data - train on all datasets
  data_path:
    value: "./TEB/"
  dataset_name:
    value: "all"  # Special value to train on all datasets
  benchmark:
    value: "TEB"
  num_classes:
    value: 2

  # Model architecture
  manifold:
    value: "lorentz"
  num_channels:
    value: 32
  embedding_dim:
    value: 528
  num_layers:
    value: 3
  kernel_size:
    value: 9
  curvature:
    value: 1.0
  use_bn:
    value: true
  mlr_type:
    value: "fc_mlr"
  use_weight_norm:
    value: true
  bn_mode:
    value: "centering_only"
  optimizer:
    value: "riemannian_adam"

  
  learning_rate:
    distribution: log_uniform_values
    min: 1e-5
    max: 5e-3
  manifold_lr:
    distribution: log_uniform_values
    min: 1e-3
    max: 1e-1
  weight_decay:
    distribution: log_uniform_values
    min: 1e-3
    max: 5e-1
  manifold_weight_decay:
    distribution: log_uniform_values
    min: 1e-4
    max: 1e-3

  batch_size:
    value: 100
  num_epochs:
    value: 100
  grad_clip:
    value: 1.0

  # Scheduler
  scheduler:
    value: "multistep"
  milestones:
    value: [60, 85]
  lr_decay:
    value: 0.1

  # Misc
  seed:
    value: 42
  evaluate_test:
    value: true  # Evaluate on test set for final reporting
