# W&B Sweep configuration for genome hyperbolic experiments
# Usage: wandb sweep sweep_config.yaml
#
# This sweep trains on ALL TEB datasets and optimizes the aggregate MCC.
# The aggregate metric is the average normalized MCC across datasets.

program: main.py
method: bayes  # Use Bayesian optimization for continuous parameters
metric:
  name: aggregate/mean_mcc
  goal: maximize

parameters:
  # Data - train on all datasets
  data_path:
    value: "./TEB/"
  dataset_name:
    value: "all"  # Special value to train on all datasets
  benchmark:
    value: "TEB"
  num_classes:
    value: 2

  # Model architecture
  manifold:
    value: "lorentz"
  num_channels:
    values: [32, 64]
  embedding_dim:
    value: 528
  num_layers:
    values: [2, 3, 4]
  kernel_size:
    values: [7, 9, 11]
  curvature:
    value: 1.0
  use_bn:
    value: true
  mlr_type:
    value: "fc_mlr"
  use_weight_norm:
    values: [true, false]
  bn_mode:
    values: ["normal", "centering_only"]

  # Optimization
  optimizer:
    values: ["riemannian_sgd", "riemannian_adam"]
  learning_rate:
    distribution: log_uniform_values
    min: 1e-4
    max: 1e-2
  manifold_lr:
    distribution: log_uniform_values
    min: 1e-4
    max: 1e-1
  weight_decay:
    distribution: log_uniform_values
    min: 1e-3
    max: 1.0
  manifold_weight_decay:
    distribution: log_uniform_values
    min: 1e-5
    max: 1e-3

  batch_size:
    value: 100
  num_epochs:
    value: 100
  grad_clip:
    value: 1.0

  # Scheduler
  scheduler:
    values: ["multistep", "cosine"]
  milestones:
    value: [60, 85]
  lr_decay:
    value: 0.1

  # Misc
  seed:
    value: 42
  evaluate_test:
    value: true  # Evaluate on test set for final reporting
