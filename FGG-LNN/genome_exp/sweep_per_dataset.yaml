# W&B Sweep configuration for per-dataset hyperparameter tuning
# Usage: wandb sweep sweep_per_dataset.yaml
#
# This sweep runs on each dataset separately, allowing you to find
# dataset-specific optimal hyperparameters before aggregating.

program: main.py
method: bayes
metric:
  name: val/mcc
  goal: maximize

parameters:
  # Data
  data_path:
    value: "./TEB/"
  dataset_name:
    values:
      - "processed_pseudogenes"
      - "unprocessed_pseudogenes"
      - "sines"
      - "lines"
      - "ltr_copia"
      - "dna_cmc"
      - "dna_hat_ac"
  benchmark:
    value: "TEB"
  length:
    value: 0  # Auto-detect from dataset name
  num_classes:
    value: 2

  # Model
  manifold:
    value: "lorentz"
  num_channels:
    values: [32, 64]
  embedding_dim:
    value: 528
  num_layers:
    values: [2, 3, 4]
  kernel_size:
    values: [7, 9, 11]
  curvature:
    value: 1.0
  use_bn:
    value: true
  mlr_type:
    value: "fc_mlr"
  use_weight_norm:
    values: [true, false]
  bn_mode:
    values: ["normal", "centering_only"]

  # Optimization
  optimizer:
    values: ["riemannian_sgd", "riemannian_adam"]
  learning_rate:
    distribution: log_uniform_values
    min: 1e-4
    max: 1e-2
  manifold_lr:
    distribution: log_uniform_values
    min: 1e-4
    max: 1e-1
  weight_decay:
    distribution: log_uniform_values
    min: 1e-3
    max: 1.0
  manifold_weight_decay:
    distribution: log_uniform_values
    min: 1e-5
    max: 1e-3

  batch_size:
    value: 100
  num_epochs:
    value: 100
  grad_clip:
    value: 1.0

  # Scheduler
  scheduler:
    values: ["multistep", "cosine"]
  milestones:
    value: [60, 85]
  lr_decay:
    value: 0.1

  # Misc
  seed:
    value: 42
  evaluate_test:
    value: true
