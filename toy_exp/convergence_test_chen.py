"""
Test script WITHOUT ReLU activation to see maximum achievable distance
"""

import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import random
from typing import List, Dict
# from pathlib import Path
# import sys

# Add layers directory to path
# parent_dir = Path(__file__).parent.parent
# sys.path.insert(0, str(parent_dir))

from layers import ChenLinear, Lorentz  # noqa: E402


# --- Constants for the Experiment ---
SEEDS = range(3)
HYPERBOLIC_DISTANCES = range(1, 30)
LEARNING_RATE = 1
MAX_ITERATIONS = 10000
LOSS_THRESHOLD = 0.01
BATCH_SIZE = 64
DIM = 4
OUTPUT_FILENAME = "./hyperplane_distance_results_no_relu.txt"


def set_seed(seed: int):
    """Sets the random seed for reproducibility."""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False


def tangent_space_mse_loss(
    y_pred: torch.Tensor, y_target: torch.Tensor, manifold: Lorentz
) -> torch.Tensor:
    """Calculates MSE in the tangent space at the origin."""
    tangent_pred = manifold.logmap0(y_pred)
    tangent_target = manifold.logmap0(y_target)
    return nn.functional.mse_loss(tangent_pred, tangent_target)


def create_target_point(
    hyperbolic_distance: int, manifold: Lorentz, dim: int
) -> torch.Tensor:
    """Creates a target point at a specified hyperbolic distance from the origin."""
    d = float(hyperbolic_distance)
    sqrt_k = manifold.k().sqrt().double()

    time = (1.0 / sqrt_k) * torch.cosh(sqrt_k * d)
    space_first = (1.0 / sqrt_k) * torch.sinh(sqrt_k * d)

    point = torch.zeros(dim + 1, dtype=torch.float64)
    point[0] = time
    point[1] = space_first

    return point


def run_experiment(
    hyperbolic_distance: int,
    seed: int,
    manifold: Lorentz,
    dim: int,
) -> int:
    """Runs a single training instance and returns the number of iterations to converge."""
    set_seed(seed)

    # Initialize model WITHOUT ReLU activation
    model = ChenLinear(
        in_features=dim,
        out_features=dim + 1,
        manifold=manifold,
    ).double()

    # Create input point
    dist_input = np.sqrt(2)
    sqrt_k = manifold.k().sqrt()
    time_input = (1.0 / sqrt_k) * torch.cosh(sqrt_k * dist_input)
    space_input = (1.0 / sqrt_k) * torch.sinh(sqrt_k * dist_input)

    x = torch.tensor(
        [time_input.item(), space_input.item()] + [0.0] * (dim - 2), dtype=torch.float64
    )
    x = x.unsqueeze(0).repeat(BATCH_SIZE, 1)

    # Create target point at specified hyperbolic distance
    y = create_target_point(hyperbolic_distance, manifold, dim)
    y = y.unsqueeze(0).repeat(BATCH_SIZE, 1)

    # Setup optimizer
    optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE)

    # üîç DIAGNOSTIC: Track gradient magnitudes
    grad_norms = []
    param_norms = []

    for i in range(MAX_ITERATIONS):
        optimizer.zero_grad()
        y_pred = model(x)
        loss = tangent_space_mse_loss(y_pred, y, manifold)

        if loss.item() < LOSS_THRESHOLD:
            # print(f"Converged at iteration {i} for distance {hyperbolic_distance}, with pred_time={y_pred[0,0].item():.6f}, target_time={y[0,0].item():.6f}")
            # print(f"  Step {i}: dist={hyperbolic_distance}, loss={loss.item():.6f}, grad_norm={grad_norms[-1]:.6e}, param_norm={param_norms[-1]:.6f}, pred_time={y_pred[0,0].item():.6f}, target_time={y[0,0].item():.6f}")
            return i + 1

        loss.backward()

        # üîß Scale gradients by parameter norm to counteract vanishing gradients
        total_param_norm = 0.0
        for name, p in model.named_parameters():
            if p.grad is not None:
                total_param_norm += p.norm().item() ** 2
        total_param_norm = np.sqrt(total_param_norm)

        # Scale factor: larger params need larger gradient steps
        scale_factor = max(1.0, total_param_norm)
        for p in model.parameters():
            if p.grad is not None:
                p.grad.mul_(scale_factor)

        # üîç Log gradient and parameter norms (after scaling)
        total_grad_norm = 0.0
        for p in model.parameters():
            if p.grad is not None:
                total_grad_norm += p.grad.norm().item() ** 2
        grad_norms.append(np.sqrt(total_grad_norm))
        param_norms.append(total_param_norm)

        # üîç Print every 1000 steps for distance 10
        if i % 1000 == 0:
            print(
                f"  Step {i}: dist={hyperbolic_distance}, loss={loss.item():.6f}, grad_norm={grad_norms[-1]:.6e}, param_norm={param_norms[-1]:.6f}, pred_time={y_pred[0, 0].item():.6f}, target_time={y[0, 0].item():.6f}"
            )

        optimizer.step()

    return MAX_ITERATIONS


def save_results_to_txt(results: Dict[int, List[int]], filename: str):
    """Saves the aggregated results to a plain text file."""
    header1 = f"{'Distance':<12} | {'Euclidean Height':<20} | {'Mean ¬± Std (Iters)':<25} | {'Status':<15}"
    header2 = f"{'':-<12} | {'':-<20} | {'':-<25} | {'':-<15}"
    separator = "-" * len(header1)

    with open(filename, "w") as f:
        f.write("=" * len(header1) + "\n")
        f.write("üìä Hyperplane Distance Convergence Results (WITHOUT ReLU)\n")
        f.write("=" * len(header1) + "\n")
        f.write("Testing ability to create hyperplanes WITHOUT ReLU activation\n")
        f.write(
            f"Batch Size: {BATCH_SIZE}, Seeds: {len(SEEDS)}, Max Iterations: {MAX_ITERATIONS}\n"
        )
        f.write("=" * len(header1) + "\n")
        f.write(header1 + "\n")
        f.write(header2 + "\n")
        f.write(separator + "\n")

        for dist, iters in sorted(results.items()):
            res = np.array(iters)
            mean_iters = np.mean(res)
            std_iters = np.std(res)
            euclidean_height = f"e^{dist} ‚âà {np.exp(dist):.2e}"

            if mean_iters >= MAX_ITERATIONS:
                status = "‚ùå FAILED"
            elif mean_iters > MAX_ITERATIONS * 0.8:
                status = "‚ö†Ô∏è  STRUGGLING"
            else:
                status = "‚úÖ OK"

            f.write(
                f"{dist:<12} | {euclidean_height:<20} | {mean_iters:7.1f} ¬± {std_iters:5.1f} | {status:<15}\n"
            )

        f.write(separator + "\n")

    print(f"\n‚úÖ Results successfully saved to '{filename}'")


def main():
    """Main function to run the full experiment WITHOUT ReLU."""
    print("üöÄ Starting Hyperplane Distance Test (WITHOUT ReLU)")
    print(
        f"Testing hyperbolic distances: {min(HYPERBOLIC_DISTANCES)} to {max(HYPERBOLIC_DISTANCES)}"
    )
    print(f"Seeds: {len(SEEDS)}, Batch Size: {BATCH_SIZE}, Dimension: {DIM}")
    print("-" * 80)

    manifold = Lorentz(k=1)
    print(f"Manifold curvature k = {manifold.k().item():.4f}")
    print("-" * 80)

    results: Dict[int, List[int]] = {d: [] for d in HYPERBOLIC_DISTANCES}

    convergence_failed = False
    first_failure_distance = None

    for dist in HYPERBOLIC_DISTANCES:
        print(
            f"\nüìè Testing hyperbolic distance: {dist} (Euclidean height ‚âà e^{dist} ‚âà {np.exp(dist):.2e})"
        )

        if convergence_failed:
            print(
                f"   Skipping... (convergence failed at distance {first_failure_distance})"
            )
            results[dist] = [MAX_ITERATIONS] * len(SEEDS)
            continue

        current_iterations = []
        for seed in SEEDS:
            iterations = run_experiment(
                hyperbolic_distance=dist,
                seed=seed,
                manifold=manifold,
                dim=DIM,
            )
            current_iterations.append(iterations)

        results[dist] = current_iterations
        mean_iters = np.mean(current_iterations)

        if mean_iters >= MAX_ITERATIONS:
            convergence_failed = True
            first_failure_distance = dist
            print(f"   ‚ùå FAILED to converge (mean iterations: {mean_iters:.1f})")
            print(f"   üìä Will skip remaining distances")
        elif mean_iters > MAX_ITERATIONS * 0.8:
            print(f"   ‚ö†Ô∏è  STRUGGLING (mean iterations: {mean_iters:.1f})")
        else:
            print(f"   ‚úÖ Converged (mean iterations: {mean_iters:.1f})")

    # --- Print Summary ---
    print("\n" + "=" * 80)
    print("üìä Convergence Results Summary (WITHOUT ReLU)")
    print("=" * 80)

    header1 = f"{'Distance':<12} | {'Euclidean Height':<20} | {'Mean ¬± Std (Iters)':<25} | {'Status':<15}"
    print(header1)
    print("-" * len(header1))

    for dist, iters in sorted(results.items()):
        res = np.array(iters)
        mean_iters = np.mean(res)
        std_iters = np.std(res)
        euclidean_height = f"e^{dist} ‚âà {np.exp(dist):.2e}"

        if mean_iters >= MAX_ITERATIONS:
            status = "‚ùå FAILED"
        elif mean_iters > MAX_ITERATIONS * 0.8:
            status = "‚ö†Ô∏è  STRUGGLING"
        else:
            status = "‚úÖ OK"

        print(
            f"{dist:<12} | {euclidean_height:<20} | {mean_iters:7.1f} ¬± {std_iters:5.1f} | {status:<15}"
        )

    print("-" * len(header1))

    save_results_to_txt(results, OUTPUT_FILENAME)

    # --- Summary Statistics ---
    print("\n" + "=" * 80)
    print("üìà Summary Statistics")
    print("=" * 80)

    max_converged_distance = None
    for dist in sorted(results.keys()):
        if np.mean(results[dist]) < MAX_ITERATIONS:
            max_converged_distance = dist
        else:
            break

    if max_converged_distance:
        print(
            f"‚úÖ Maximum hyperbolic distance with consistent convergence: {max_converged_distance}"
        )
        print(
            f"   (Euclidean height ‚âà e^{max_converged_distance} ‚âà {np.exp(max_converged_distance):.2e})"
        )
    else:
        print("‚ùå Failed to converge even at the smallest distance tested")

    print("\n" + "=" * 80)


if __name__ == "__main__":
    main()
