program: main.py
method: bayes
metric:
  name: best_val_acc
  goal: maximize

parameters:
  # Optimizer selection
  optimizer:
    values: ["adam", "sgd"]

  # Learning rate (log scale)
  learning_rate:
    distribution: log_uniform_values
    min: 1e-3
    max: 2e-1

  # Weight decay (log scale)
  weight_decay:
    distribution: log_uniform_values
    min: 1e-4
    max: 1e-3

  # Scheduler
  scheduler:
    values: ["steplr", "cosine"]

  # SGD momentum (only relevant when optimizer=sgd, but Bayesian will figure this out)
  momentum:
    distribution: uniform
    min: 0.9
    max: 0.99

  # Fixed parameters for sweep
  num_epochs:
    value: 200
  warmup_epochs:
    value: 10
  batch_size:
    value: 128
  hidden_dim:
    value: 64
  curvature:
    value: 1.0
  train_subset_fraction:
    value: 1.0
  init_method:
    value: "lorentz_kaiming"
  val_fraction:
    value: 0.1
  data_split_seed:
    value: 42
  seed:
    value: 0
  early_stopping:
    value: true
  early_stopping_patience:
    value: 10
  grad_clip:
    value: 1.0
  compile:
    value: true
  evaluate_test:
    value: false
  lr_decay:
    value: 0.2
