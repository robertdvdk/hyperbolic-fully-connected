{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2de64416",
   "metadata": {},
   "source": [
    "# OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9920274",
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers import Lorentz_fully_connected\n",
    "from layers import Lorentz\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79475868",
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers import Lorentz_fully_connected\n",
    "from layers import Lorentz\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "\n",
    "class EuclideanToLorentz(nn.Module):\n",
    "    \"\"\"Project Euclidean features onto Lorentz manifold.\"\"\"\n",
    "    \n",
    "    def __init__(self, in_features, out_features, manifold):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_features: Euclidean input dimension (e.g., 784 for MNIST)\n",
    "            out_features: Lorentz output dimension INCLUDING time (e.g., 100 means 99 space + 1 time)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.manifold = manifold\n",
    "        self.linear = nn.Linear(in_features, out_features - 1)  # Output space components only\n",
    "        \n",
    "        # Small init to keep points near origin initially (more stable)\n",
    "        nn.init.xavier_uniform_(self.linear.weight, gain=0.1)\n",
    "        nn.init.zeros_(self.linear.bias)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: [batch, in_features] Euclidean vectors\n",
    "        Returns:\n",
    "            [batch, out_features] points on Lorentz manifold\n",
    "        \"\"\"\n",
    "        space = self.linear(x)  # [batch, out_features - 1]\n",
    "        return self.manifold.projection_space_orthogonal(space)  # [batch, out_features]\n",
    "    \n",
    "class EuclideanToLorentzConv(nn.Module):\n",
    "    \"\"\"Project Euclidean image onto Lorentz manifold via 1x1 conv.\"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, manifold):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_channels: Euclidean channels (e.g., 3 for RGB)\n",
    "            out_channels: Lorentz channels INCLUDING time (e.g., 16 means 15 space + 1 time)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.manifold = manifold\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels - 1, kernel_size=1)\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.conv.weight, gain=0.1)\n",
    "        nn.init.zeros_(self.conv.bias)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: [batch, in_channels, H, W] Euclidean image\n",
    "        Returns:\n",
    "            [batch, out_channels, H, W] on Lorentz manifold (each pixel is a Lorentz point)\n",
    "        \"\"\"\n",
    "        space = self.conv(x)  # [batch, out_channels - 1, H, W]\n",
    "        \n",
    "        # Compute time component for each pixel\n",
    "        # time = sqrt(||space||^2 + 1/k)\n",
    "        time = torch.sqrt((space ** 2).sum(dim=1, keepdim=True) + 1.0 / self.manifold.k())\n",
    "        \n",
    "        return torch.cat([time, space], dim=1)  # [batch, out_channels, H, W]\n",
    "\n",
    "class LorentzResidualMidpoint(nn.Module):\n",
    "    \"\"\"Residual via weighted Lorentz midpoint.\"\"\"\n",
    "    \n",
    "    def __init__(self, dim, manifold, activation):\n",
    "        super().__init__()\n",
    "        self.manifold = manifold\n",
    "        self.fc = Lorentz_fully_connected(\n",
    "            in_features=dim,\n",
    "            out_features=dim,\n",
    "            manifold=manifold,\n",
    "            reset_params=\"kaiming\",\n",
    "            activation=activation\n",
    "        )\n",
    "        # Learnable weight (0.5 = equal weighting)\n",
    "        self.alpha_logit = nn.Parameter(torch.tensor(0.0))  # sigmoid(0) = 0.5\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc(x)\n",
    "        \n",
    "        # Weighted midpoint on manifold\n",
    "        alpha = torch.sigmoid(self.alpha_logit)\n",
    "        # Stack for centroid computation: [batch, 2, dim]\n",
    "        stacked = torch.stack([x, out], dim=-2)\n",
    "        \n",
    "        # Weights: [1, 2] -> broadcast to [batch, 2]\n",
    "        weights = torch.tensor([[1 - alpha, alpha]], device=x.device)\n",
    "        return self.manifold.lorentz_midpoint(stacked, weights)\n",
    "    \n",
    "\n",
    "class LorentzConv2d(nn.Module):\n",
    "    \"\"\"\n",
    "    Lorentz Conv2d using direct concatenation + existing Lorentz FC.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        kernel_size: int | tuple[int, int],\n",
    "        stride: int | tuple[int, int],\n",
    "        padding: int | tuple[int, int],\n",
    "        manifold: Lorentz,\n",
    "        activation,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.manifold = manifold or Lorentz(k=1.0)\n",
    "        \n",
    "        if isinstance(kernel_size, int):\n",
    "            kernel_size = (kernel_size, kernel_size)\n",
    "        if isinstance(stride, int):\n",
    "            stride = (stride, stride)\n",
    "        if isinstance(padding, int):\n",
    "            padding = (padding, padding)\n",
    "        \n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        \n",
    "        # After concatenating k*k Lorentz points:\n",
    "        # concat_dim = 1 + (in_channels - 1) * k * k\n",
    "        concat_dim = 1 + (in_channels - 1) * kernel_size[0] * kernel_size[1]\n",
    "        \n",
    "        # Reuse existing Lorentz FC\n",
    "        self.fc = Lorentz_fully_connected(\n",
    "            in_features=concat_dim,\n",
    "            out_features=out_channels,\n",
    "            manifold=self.manifold,\n",
    "            activation=activation,\n",
    "            reset_params=\"orthogonal\"\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: [batch, in_channels, H, W]\n",
    "        Returns:\n",
    "            [batch, out_channels, H', W']\n",
    "        \"\"\"\n",
    "        batch, C, H, W = x.shape\n",
    "        kH, kW = self.kernel_size\n",
    "        sH, sW = self.stride\n",
    "        pH, pW = self.padding\n",
    "        \n",
    "        # Pad with origin points\n",
    "        if pH > 0 or pW > 0:\n",
    "            sqrt_k_inv = (1.0 / self.manifold.k()).sqrt()\n",
    "            x = F.pad(x, (pW, pW, pH, pH), mode='constant', value=0.0)\n",
    "            _, _, H_pad, W_pad = x.shape\n",
    "            \n",
    "            # Fix time component in padded regions\n",
    "            mask = torch.ones(1, 1, H_pad, W_pad, device=x.device, dtype=x.dtype)\n",
    "            mask[:, :, pH:pH+H, pW:pW+W] = 0\n",
    "            x[:, 0:1] = x[:, 0:1] * (1 - mask) + sqrt_k_inv * mask\n",
    "        \n",
    "        # Unfold: [batch, C * kH * kW, num_patches]\n",
    "        patches = F.unfold(x, kernel_size=self.kernel_size, stride=self.stride)\n",
    "        \n",
    "        # Reshape to [batch, num_patches, kH * kW, C]\n",
    "        num_patches = patches.shape[-1]\n",
    "        patches = patches.view(batch, C, kH * kW, num_patches)\n",
    "        patches = patches.permute(0, 3, 2, 1)  # [batch, num_patches, k*k, C]\n",
    "        \n",
    "        # Direct concat: [batch * num_patches, k*k, C] -> [batch * num_patches, concat_dim]\n",
    "        patches_flat = patches.reshape(batch * num_patches, kH * kW, C)\n",
    "        concat_points = self.manifold.direct_concat(patches_flat)\n",
    "        \n",
    "        # Apply Lorentz FC: [batch * num_patches, concat_dim] -> [batch * num_patches, out_channels]\n",
    "        out = self.fc(concat_points)\n",
    "        \n",
    "        # Reshape to spatial: [batch, out_channels, H', W']\n",
    "        H_out = (H + 2 * pH - kH) // sH + 1\n",
    "        W_out = (W + 2 * pW - kW) // sW + 1\n",
    "        out = out.view(batch, H_out, W_out, -1).permute(0, 3, 1, 2)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "class LorentzMLPWithResidual(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        input_dim,\n",
    "        hidden_dim,\n",
    "        num_classes,\n",
    "        num_layers=3,\n",
    "        manifold=None,\n",
    "        activation=F.relu\n",
    "    ):\n",
    "    \n",
    "        super().__init__()\n",
    "        self.manifold = manifold or Lorentz(k=1.0)\n",
    "        \n",
    "        # Input projection\n",
    "        self.input_proj = EuclideanToLorentz(input_dim, hidden_dim, self.manifold)\n",
    "        \n",
    "        # Select residual block type\n",
    "        block_cls = LorentzResidualMidpoint\n",
    "        \n",
    "        # Hidden layers with residuals\n",
    "        self.layers = nn.ModuleList([\n",
    "            block_cls(hidden_dim, self.manifold, activation=activation)\n",
    "            for _ in range(num_layers - 1)\n",
    "        ])\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = Lorentz_fully_connected(\n",
    "            in_features=hidden_dim,\n",
    "            out_features=num_classes + 1,\n",
    "            manifold=self.manifold,\n",
    "            reset_params=\"kaiming\",\n",
    "            do_mlr=True\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if x.dim() > 2:\n",
    "            x = x.view(x.size(0), -1)\n",
    "        \n",
    "        x = self.input_proj(x)\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        \n",
    "        return self.classifier(x)\n",
    "    \n",
    "\n",
    "class LorentzConvNet(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        input_dim,\n",
    "        hidden_dim,\n",
    "        num_classes,\n",
    "        num_layers=3,\n",
    "        manifold=None,\n",
    "        activation=F.relu\n",
    "    ):\n",
    "    \n",
    "        super().__init__()\n",
    "        self.manifold = manifold or Lorentz(k=1.0)\n",
    "        \n",
    "        # Input projection\n",
    "        self.input_proj = EuclideanToLorentzConv(input_dim, hidden_dim, self.manifold)\n",
    "        \n",
    "        # Select residual block type\n",
    "        self.layer1 = LorentzConv2d(hidden_dim, hidden_dim, 3, 1, 0, manifold, activation)\n",
    "        \n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = Lorentz_fully_connected(\n",
    "            in_features=hidden_dim,\n",
    "            out_features=num_classes + 1,\n",
    "            manifold=self.manifold,\n",
    "            reset_params=\"kaiming\",\n",
    "            do_mlr=True\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        print(x.shape)\n",
    "        x = self.input_proj(x)\n",
    "        print(x.shape)\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        print(x.shape)\n",
    "        \n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdc092c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EuclideanToLorentz(nn.Module):\n",
    "    \"\"\"Project Euclidean features onto Lorentz manifold.\"\"\"\n",
    "    \n",
    "    def __init__(self, in_features, out_features, manifold):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_features: Euclidean input dimension (e.g., 784 for MNIST)\n",
    "            out_features: Lorentz output dimension INCLUDING time (e.g., 100 means 99 space + 1 time)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.manifold = manifold\n",
    "        self.linear = nn.Linear(in_features, out_features - 1)  # Output space components only\n",
    "        \n",
    "        # Small init to keep points near origin initially (more stable)\n",
    "        nn.init.xavier_uniform_(self.linear.weight, gain=0.1)\n",
    "        nn.init.zeros_(self.linear.bias)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: [batch, in_features] Euclidean vectors\n",
    "        Returns:\n",
    "            [batch, out_features] points on Lorentz manifold\n",
    "        \"\"\"\n",
    "        space = self.linear(x)  # [batch, out_features - 1]\n",
    "        return self.manifold.projection_space_orthogonal(space)  # [batch, out_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f9d6c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LorentzResidualMidpoint(nn.Module):\n",
    "    \"\"\"Residual via weighted Lorentz midpoint.\"\"\"\n",
    "    \n",
    "    def __init__(self, dim, manifold, activation):\n",
    "        super().__init__()\n",
    "        self.manifold = manifold\n",
    "        self.fc = Lorentz_fully_connected(\n",
    "            in_features=dim,\n",
    "            out_features=dim,\n",
    "            manifold=manifold,\n",
    "            reset_params=\"kaiming\",\n",
    "            activation=activation\n",
    "        )\n",
    "        # Learnable weight (0.5 = equal weighting)\n",
    "        self.alpha_logit = nn.Parameter(torch.tensor(0.0))  # sigmoid(0) = 0.5\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc(x)\n",
    "        \n",
    "        # Weighted midpoint on manifold\n",
    "        alpha = torch.sigmoid(self.alpha_logit)\n",
    "        # Stack for centroid computation: [batch, 2, dim]\n",
    "        stacked = torch.stack([x, out], dim=-2)\n",
    "        \n",
    "        # Weights: [1, 2] -> broadcast to [batch, 2]\n",
    "        weights = torch.tensor([[1 - alpha, alpha]], device=x.device)\n",
    "        return self.manifold.lorentz_midpoint(stacked, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cf2e629",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LorentzMLPWithResidual(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        input_dim,\n",
    "        hidden_dim,\n",
    "        num_classes,\n",
    "        num_layers=3,\n",
    "        manifold=None,\n",
    "        activation=F.relu\n",
    "    ):\n",
    "    \n",
    "        super().__init__()\n",
    "        self.manifold = manifold or Lorentz(k=1.0)\n",
    "        \n",
    "        # Input projection\n",
    "        self.input_proj = EuclideanToLorentz(input_dim, hidden_dim, self.manifold)\n",
    "        \n",
    "        # Select residual block type\n",
    "        block_cls = LorentzResidualMidpoint\n",
    "        \n",
    "        # Hidden layers with residuals\n",
    "        self.layers = nn.ModuleList([\n",
    "            block_cls(hidden_dim, self.manifold, activation=activation)\n",
    "            for _ in range(num_layers - 1)\n",
    "        ])\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = Lorentz_fully_connected(\n",
    "            in_features=hidden_dim,\n",
    "            out_features=num_classes + 1,\n",
    "            manifold=self.manifold,\n",
    "            reset_params=\"kaiming\",\n",
    "            do_mlr=True\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if x.dim() > 2:\n",
    "            x = x.view(x.size(0), -1)\n",
    "        \n",
    "        x = self.input_proj(x)\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        \n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89e519cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LorentzConv2d(nn.Module):\n",
    "    \"\"\"Residual via weighted Lorentz midpoint.\"\"\"\n",
    "    \n",
    "    def __init__(self, dim, manifold, activation):\n",
    "        super().__init__()\n",
    "        self.manifold = manifold\n",
    "        self.fc = Lorentz_fully_connected(\n",
    "            in_features=dim,\n",
    "            out_features=dim,\n",
    "            manifold=manifold,\n",
    "            reset_params=\"kaiming\",\n",
    "            activation=activation\n",
    "        )\n",
    "        # Learnable weight (0.5 = equal weighting)\n",
    "        self.alpha_logit = nn.Parameter(torch.tensor(0.0))  # sigmoid(0) = 0.5\n",
    "    \n",
    "    def forward(self, x):\n",
    "        print(x.shape)\n",
    "\n",
    "        out = self.fc(x)\n",
    "        \n",
    "        # Weighted midpoint on manifold\n",
    "        alpha = torch.sigmoid(self.alpha_logit)\n",
    "        # Stack for centroid computation: [batch, 2, dim]\n",
    "        stacked = torch.stack([x, out], dim=-2)\n",
    "        \n",
    "        # Weights: [1, 2] -> broadcast to [batch, 2]\n",
    "        weights = torch.tensor([[1 - alpha, alpha]], device=x.device)\n",
    "        return self.manifold.lorentz_midpoint(stacked, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e32ee5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 16, 32, 32])\n",
      "torch.Size([128, 16, 30, 30])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (61440x30 and 16x100)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, (x, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[32m     18\u001b[39m     optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     logits = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m.squeeze()\n\u001b[32m     20\u001b[39m     loss = F.cross_entropy(logits, y.cuda())\n\u001b[32m     21\u001b[39m     loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hyperbolic-fully-connected/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hyperbolic-fully-connected/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 268\u001b[39m, in \u001b[36mLorentzConvNet.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    265\u001b[39m x = \u001b[38;5;28mself\u001b[39m.layer1(x)\n\u001b[32m    266\u001b[39m \u001b[38;5;28mprint\u001b[39m(x.shape)\n\u001b[32m--> \u001b[39m\u001b[32m268\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hyperbolic-fully-connected/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hyperbolic-fully-connected/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hyperbolic-fully-connected/layers/lorentz_fc.py:112\u001b[39m, in \u001b[36mLorentz_fully_connected.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m    111\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.do_mlr:\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmlr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    113\u001b[39m     output_space = \u001b[38;5;28mself\u001b[39m.compute_output_space(x)\n\u001b[32m    114\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.manifold.projection_space_orthogonal(output_space)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hyperbolic-fully-connected/layers/lorentz_fc.py:121\u001b[39m, in \u001b[36mLorentz_fully_connected.mlr\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    120\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmlr\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msigned_dist2hyperplanes_scaled_angle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hyperbolic-fully-connected/layers/lorentz_fc.py:97\u001b[39m, in \u001b[36mLorentz_fully_connected.signed_dist2hyperplanes_scaled_angle\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     95\u001b[39m V = \u001b[38;5;28mself\u001b[39m.create_spacelike_vector()\n\u001b[32m     96\u001b[39m sqrt_k = \u001b[38;5;28mself\u001b[39m.manifold.k().sqrt()\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[32m1\u001b[39m / sqrt_k * torch.asinh(\u001b[43msqrt_k\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[43m@\u001b[49m\u001b[43m \u001b[49m\u001b[43mV\u001b[49m)\n",
      "\u001b[31mRuntimeError\u001b[39m: mat1 and mat2 shapes cannot be multiplied (61440x30 and 16x100)"
     ]
    }
   ],
   "source": [
    "manifold = Lorentz(k=1.0)\n",
    "trainset = torchvision.datasets.CIFAR100(\"./cifar\", train=True, download=True, transform=torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(), \n",
    "    torchvision.transforms.Normalize((0.5074, 0.4867, 0.4411), (0.267, 0.256, 0.276))]\n",
    "    ))\n",
    "valset = torchvision.datasets.CIFAR100(\"./cifar\", train=False, download=True, transform=torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(), \n",
    "    torchvision.transforms.Normalize((0.5074, 0.4867, 0.4411), (0.267, 0.256, 0.276)),]\n",
    "    ))\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(valset, batch_size=128, shuffle=False)\n",
    "model = LorentzConvNet(input_dim=3, hidden_dim=16, num_classes=100, num_layers=5, manifold=manifold, activation=nn.Identity()).cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "data, target = next(iter(train_loader))\n",
    "for _ in range(10):\n",
    "    running_loss, acc, counts = 0.0, 0.0, 0\n",
    "    for step, (x, y) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x.cuda()).squeeze()\n",
    "        loss = F.cross_entropy(logits, y.cuda())\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        if running_loss == 0.0:\n",
    "            running_loss = loss.item()\n",
    "        else:\n",
    "            running_loss = 0.99*running_loss + 0.01*loss.item()\n",
    "        acc += (logits.argmax(dim=1) == y.cuda()).float().sum()\n",
    "        counts += x.shape[0]\n",
    "        if step % 200 == 0:\n",
    "            print(\"running loss:\", running_loss)\n",
    "    print(\"training acc:\", acc / counts)\n",
    "    with torch.no_grad():\n",
    "        running_loss, acc, counts = 0.0, 0.0, 0\n",
    "        for x, y in val_loader:\n",
    "            logits = model(x.cuda()).squeeze()\n",
    "            loss = F.cross_entropy(logits, y.cuda(), reduction='sum')\n",
    "            running_loss += loss.item()\n",
    "            acc += (logits.argmax(dim=1) == y.cuda()).float().sum()\n",
    "            counts += x.shape[0]\n",
    "        \n",
    "        print(\"val loss:\", running_loss / counts)\n",
    "        print(\"val acc:\", acc / counts)\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b93c346a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running loss: 4.60907506942749\n",
      "running loss: 4.254255323586646\n",
      "training acc: tensor(0.0696, device='cuda:0')\n",
      "val loss: 3.973182211303711\n",
      "val acc: tensor(0.0831, device='cuda:0')\n",
      "running loss: 3.8841326236724854\n",
      "running loss: 3.876686127612739\n",
      "training acc: tensor(0.1086, device='cuda:0')\n",
      "val loss: 3.8230095092773437\n",
      "val acc: tensor(0.1161, device='cuda:0')\n",
      "running loss: 3.610873222351074\n",
      "running loss: 3.7479927436284575\n",
      "training acc: tensor(0.1282, device='cuda:0')\n",
      "val loss: 3.783591979217529\n",
      "val acc: tensor(0.1313, device='cuda:0')\n",
      "running loss: 3.6887619495391846\n",
      "running loss: 3.7151483322671344\n",
      "training acc: tensor(0.1398, device='cuda:0')\n",
      "val loss: 3.7308448249816895\n",
      "val acc: tensor(0.1421, device='cuda:0')\n",
      "running loss: 3.588874340057373\n",
      "running loss: 3.664122220498964\n",
      "training acc: tensor(0.1469, device='cuda:0')\n",
      "val loss: 3.728555487060547\n",
      "val acc: tensor(0.1392, device='cuda:0')\n",
      "running loss: 3.761927843093872\n",
      "running loss: 3.668708463334047\n",
      "training acc: tensor(0.1516, device='cuda:0')\n",
      "val loss: 3.707353867340088\n",
      "val acc: tensor(0.1448, device='cuda:0')\n",
      "running loss: 3.6123228073120117\n",
      "running loss: 3.6298594420163703\n",
      "training acc: tensor(0.1565, device='cuda:0')\n",
      "val loss: 3.693610414123535\n",
      "val acc: tensor(0.1487, device='cuda:0')\n",
      "running loss: 3.5105295181274414\n",
      "running loss: 3.608858704490277\n",
      "training acc: tensor(0.1620, device='cuda:0')\n",
      "val loss: 3.6828490631103517\n",
      "val acc: tensor(0.1515, device='cuda:0')\n",
      "running loss: 3.732304573059082\n",
      "running loss: 3.619059831578832\n",
      "training acc: tensor(0.1658, device='cuda:0')\n",
      "val loss: 3.686985467529297\n",
      "val acc: tensor(0.1516, device='cuda:0')\n",
      "running loss: 3.653902292251587\n",
      "running loss: 3.5863455411897904\n",
      "training acc: tensor(0.1682, device='cuda:0')\n",
      "val loss: 3.6571015853881836\n",
      "val acc: tensor(0.1576, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "manifold = Lorentz(k=1.0)\n",
    "trainset = torchvision.datasets.CIFAR100(\"./cifar\", train=True, download=True, transform=torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(), \n",
    "    torchvision.transforms.Normalize((0.5074, 0.4867, 0.4411), (0.267, 0.256, 0.276)),\n",
    "    torchvision.transforms.Lambda(lambda x: x.view(-1))]  # Flatten to [784]\n",
    "    ))\n",
    "valset = torchvision.datasets.CIFAR100(\"./cifar\", train=False, download=True, transform=torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(), \n",
    "    torchvision.transforms.Normalize((0.5074, 0.4867, 0.4411), (0.267, 0.256, 0.276)),\n",
    "    torchvision.transforms.Lambda(lambda x: x.view(-1))]  # Flatten to [784]\n",
    "    ))\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(valset, batch_size=128, shuffle=False)\n",
    "model = LorentzMLPWithResidual(input_dim=3072, hidden_dim=100, num_classes=100, num_layers=5, manifold=manifold, activation=nn.Identity()).cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "data, target = next(iter(train_loader))\n",
    "for _ in range(10):\n",
    "    running_loss, acc, counts = 0.0, 0.0, 0\n",
    "    for step, (x, y) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x.cuda()).squeeze()\n",
    "        loss = F.cross_entropy(logits, y.cuda())\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        if running_loss == 0.0:\n",
    "            running_loss = loss.item()\n",
    "        else:\n",
    "            running_loss = 0.99*running_loss + 0.01*loss.item()\n",
    "        acc += (logits.argmax(dim=1) == y.cuda()).float().sum()\n",
    "        counts += x.shape[0]\n",
    "        if step % 200 == 0:\n",
    "            print(\"running loss:\", running_loss)\n",
    "    print(\"training acc:\", acc / counts)\n",
    "    with torch.no_grad():\n",
    "        running_loss, acc, counts = 0.0, 0.0, 0\n",
    "        for x, y in val_loader:\n",
    "            logits = model(x.cuda()).squeeze()\n",
    "            loss = F.cross_entropy(logits, y.cuda(), reduction='sum')\n",
    "            running_loss += loss.item()\n",
    "            acc += (logits.argmax(dim=1) == y.cuda()).float().sum()\n",
    "            counts += x.shape[0]\n",
    "        \n",
    "        print(\"val loss:\", running_loss / counts)\n",
    "        print(\"val acc:\", acc / counts)\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05897c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running loss: 4.607980728149414\n",
      "running loss: 4.343890246799889\n",
      "training acc: tensor(0.0586, device='cuda:0')\n",
      "val loss: 3.9989096130371093\n",
      "val acc: tensor(0.0811, device='cuda:0')\n",
      "running loss: 4.106558799743652\n",
      "running loss: 3.9393786040225773\n",
      "training acc: tensor(0.0965, device='cuda:0')\n",
      "val loss: 3.87111513671875\n",
      "val acc: tensor(0.1046, device='cuda:0')\n",
      "running loss: 3.8728296756744385\n",
      "running loss: 3.82414895722909\n",
      "training acc: tensor(0.1138, device='cuda:0')\n",
      "val loss: 3.8022483505249025\n",
      "val acc: tensor(0.1194, device='cuda:0')\n",
      "running loss: 3.7738242149353027\n",
      "running loss: 3.742089424995754\n",
      "training acc: tensor(0.1291, device='cuda:0')\n",
      "val loss: 3.7483328674316407\n",
      "val acc: tensor(0.1305, device='cuda:0')\n",
      "running loss: 3.7000441551208496\n",
      "running loss: 3.6871290674865054\n",
      "training acc: tensor(0.1384, device='cuda:0')\n",
      "val loss: 3.6990942077636717\n",
      "val acc: tensor(0.1390, device='cuda:0')\n",
      "running loss: 3.7008056640625\n",
      "running loss: 3.628138753147013\n",
      "training acc: tensor(0.1502, device='cuda:0')\n",
      "val loss: 3.6591722747802735\n",
      "val acc: tensor(0.1467, device='cuda:0')\n",
      "running loss: 3.647783041000366\n",
      "running loss: 3.583228551903179\n",
      "training acc: tensor(0.1570, device='cuda:0')\n",
      "val loss: 3.6304768920898436\n",
      "val acc: tensor(0.1537, device='cuda:0')\n",
      "running loss: 3.495762825012207\n",
      "running loss: 3.5238528335874513\n",
      "training acc: tensor(0.1651, device='cuda:0')\n",
      "val loss: 3.58839651260376\n",
      "val acc: tensor(0.1581, device='cuda:0')\n",
      "running loss: 3.3803887367248535\n",
      "running loss: 3.477131901845774\n",
      "training acc: tensor(0.1735, device='cuda:0')\n",
      "val loss: 3.575208171081543\n",
      "val acc: tensor(0.1628, device='cuda:0')\n",
      "running loss: 3.3984193801879883\n",
      "running loss: 3.445811212703991\n",
      "training acc: tensor(0.1791, device='cuda:0')\n",
      "val loss: 3.5609279823303224\n",
      "val acc: tensor(0.1656, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "manifold = Lorentz(k=1.0)\n",
    "trainset = torchvision.datasets.CIFAR100(\"./cifar\", train=True, download=True, transform=torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(), \n",
    "    torchvision.transforms.Normalize((0.5074, 0.4867, 0.4411), (0.267, 0.256, 0.276)),\n",
    "    torchvision.transforms.Lambda(lambda x: x.view(-1))]  # Flatten to [784]\n",
    "    ))\n",
    "valset = torchvision.datasets.CIFAR100(\"./cifar\", train=False, download=True, transform=torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(), \n",
    "    torchvision.transforms.Normalize((0.5074, 0.4867, 0.4411), (0.267, 0.256, 0.276)),\n",
    "    torchvision.transforms.Lambda(lambda x: x.view(-1))]  # Flatten to [784]\n",
    "    ))\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(valset, batch_size=128, shuffle=False)\n",
    "model = LorentzMLPWithResidual(input_dim=3072, hidden_dim=100, num_classes=100, num_layers=5, manifold=manifold, activation=nn.ReLU()).cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "data, target = next(iter(train_loader))\n",
    "for _ in range(10):\n",
    "    running_loss, acc, counts = 0.0, 0.0, 0\n",
    "    for step, (x, y) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x.cuda()).squeeze()\n",
    "        loss = F.cross_entropy(logits, y.cuda())\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        if running_loss == 0.0:\n",
    "            running_loss = loss.item()\n",
    "        else:\n",
    "            running_loss = 0.99*running_loss + 0.01*loss.item()\n",
    "        acc += (logits.argmax(dim=1) == y.cuda()).float().sum()\n",
    "        counts += x.shape[0]\n",
    "        if step % 200 == 0:\n",
    "            print(\"running loss:\", running_loss)\n",
    "    print(\"training acc:\", acc / counts)\n",
    "    with torch.no_grad():\n",
    "        running_loss, acc, counts = 0.0, 0.0, 0\n",
    "        for x, y in val_loader:\n",
    "            logits = model(x.cuda()).squeeze()\n",
    "            loss = F.cross_entropy(logits, y.cuda(), reduction='sum')\n",
    "            running_loss += loss.item()\n",
    "            acc += (logits.argmax(dim=1) == y.cuda()).float().sum()\n",
    "            counts += x.shape[0]\n",
    "        \n",
    "        print(\"val loss:\", running_loss / counts)\n",
    "        print(\"val acc:\", acc / counts)\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e13d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "manifold = Lorentz(k=1.0)\n",
    "trainset = torchvision.datasets.CIFAR100(\"./cifar\", train=True, download=True, transform=torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(), \n",
    "    torchvision.transforms.Normalize((0.5074, 0.4867, 0.4411), (0.267, 0.256, 0.276)),\n",
    "    torchvision.transforms.Lambda(lambda x: x.view(-1))]  # Flatten to [784]\n",
    "    ))\n",
    "valset = torchvision.datasets.CIFAR100(\"./cifar\", train=False, download=True, transform=torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(), \n",
    "    torchvision.transforms.Normalize((0.5074, 0.4867, 0.4411), (0.267, 0.256, 0.276)),\n",
    "    torchvision.transforms.Lambda(lambda x: x.view(-1))]  # Flatten to [784]\n",
    "    ))\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(valset, batch_size=128, shuffle=False)\n",
    "model = LorentzMLPWithResidual(input_dim=3072, hidden_dim=100, num_classes=100, num_layers=5, manifold=manifold, activation=nn.ReLU()).cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "data, target = next(iter(train_loader))\n",
    "for _ in range(10):\n",
    "    running_loss, acc, counts = 0.0, 0.0, 0\n",
    "    for step, (x, y) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x.cuda()).squeeze()\n",
    "        loss = F.cross_entropy(logits, y.cuda())\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        if running_loss == 0.0:\n",
    "            running_loss = loss.item()\n",
    "        else:\n",
    "            running_loss = 0.99*running_loss + 0.01*loss.item()\n",
    "        acc += (logits.argmax(dim=1) == y.cuda()).float().sum()\n",
    "        counts += x.shape[0]\n",
    "        if step % 200 == 0:\n",
    "            print(\"running loss:\", running_loss)\n",
    "    print(\"training acc:\", acc / counts)\n",
    "    with torch.no_grad():\n",
    "        running_loss, acc, counts = 0.0, 0.0, 0\n",
    "        for x, y in val_loader:\n",
    "            logits = model(x.cuda()).squeeze()\n",
    "            loss = F.cross_entropy(logits, y.cuda(), reduction='sum')\n",
    "            running_loss += loss.item()\n",
    "            acc += (logits.argmax(dim=1) == y.cuda()).float().sum()\n",
    "            counts += x.shape[0]\n",
    "        \n",
    "        print(\"val loss:\", running_loss / counts)\n",
    "        print(\"val acc:\", acc / counts)\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "57c79872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running loss: 2.3018221855163574\n",
      "running loss: 1.9437158898051308\n",
      "training acc: tensor(0.3459, device='cuda:0')\n",
      "val loss: 1.6798603118896485\n",
      "val acc: tensor(0.4022, device='cuda:0')\n",
      "running loss: 1.688948631286621\n",
      "running loss: 1.6294594895824834\n",
      "training acc: tensor(0.4332, device='cuda:0')\n",
      "val loss: 1.5643589988708495\n",
      "val acc: tensor(0.4461, device='cuda:0')\n",
      "running loss: 1.5382037162780762\n",
      "running loss: 1.515978446410169\n",
      "training acc: tensor(0.4677, device='cuda:0')\n",
      "val loss: 1.499418251800537\n",
      "val acc: tensor(0.4711, device='cuda:0')\n",
      "running loss: 1.3877149820327759\n",
      "running loss: 1.4477123211971614\n",
      "training acc: tensor(0.4901, device='cuda:0')\n",
      "val loss: 1.4749658712387086\n",
      "val acc: tensor(0.4763, device='cuda:0')\n",
      "running loss: 1.5040117502212524\n",
      "running loss: 1.4133201105756714\n",
      "training acc: tensor(0.5064, device='cuda:0')\n",
      "val loss: 1.4511191493988038\n",
      "val acc: tensor(0.4891, device='cuda:0')\n",
      "running loss: 1.3741260766983032\n",
      "running loss: 1.366600154489454\n",
      "training acc: tensor(0.5265, device='cuda:0')\n",
      "val loss: 1.4146394401550293\n",
      "val acc: tensor(0.5026, device='cuda:0')\n",
      "running loss: 1.334616780281067\n",
      "running loss: 1.324064755337816\n",
      "training acc: tensor(0.5404, device='cuda:0')\n",
      "val loss: 1.4095972551345826\n",
      "val acc: tensor(0.5044, device='cuda:0')\n",
      "running loss: 1.1477208137512207\n",
      "running loss: 1.2678779967606655\n",
      "training acc: tensor(0.5523, device='cuda:0')\n",
      "val loss: 1.4014331493377685\n",
      "val acc: tensor(0.5110, device='cuda:0')\n",
      "running loss: 1.1974101066589355\n",
      "running loss: 1.2637976366629888\n",
      "training acc: tensor(0.5606, device='cuda:0')\n",
      "val loss: 1.4025544834136963\n",
      "val acc: tensor(0.5156, device='cuda:0')\n",
      "running loss: 1.3965749740600586\n",
      "running loss: 1.2626987525560631\n",
      "training acc: tensor(0.5700, device='cuda:0')\n",
      "val loss: 1.4020939409255981\n",
      "val acc: tensor(0.5105, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "manifold = Lorentz(k=1.0)\n",
    "trainset = torchvision.datasets.CIFAR10(\"./cifar\", train=True, download=True, transform=torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(), \n",
    "    torchvision.transforms.Normalize((0.5074, 0.4867, 0.4411), (0.267, 0.256, 0.276)),\n",
    "    torchvision.transforms.Lambda(lambda x: x.view(-1))]  # Flatten to [784]\n",
    "    ))\n",
    "valset = torchvision.datasets.CIFAR10(\"./cifar\", train=False, download=True, transform=torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(), \n",
    "    torchvision.transforms.Normalize((0.5074, 0.4867, 0.4411), (0.267, 0.256, 0.276)),\n",
    "    torchvision.transforms.Lambda(lambda x: x.view(-1))]  # Flatten to [784]\n",
    "    ))\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(valset, batch_size=128, shuffle=False)\n",
    "model = LorentzMLPWithResidual(input_dim=3072, hidden_dim=100, num_classes=10, num_layers=5, manifold=manifold, activation=F.relu).cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "data, target = next(iter(train_loader))\n",
    "for _ in range(10):\n",
    "    running_loss, acc, counts = 0.0, 0.0, 0\n",
    "    for step, (x, y) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x.cuda()).squeeze()\n",
    "        loss = F.cross_entropy(logits, y.cuda())\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        if running_loss == 0.0:\n",
    "            running_loss = loss.item()\n",
    "        else:\n",
    "            running_loss = 0.99*running_loss + 0.01*loss.item()\n",
    "        acc += (logits.argmax(dim=1) == y.cuda()).float().sum()\n",
    "        counts += x.shape[0]\n",
    "        if step % 200 == 0:\n",
    "            print(\"running loss:\", running_loss)\n",
    "    print(\"training acc:\", acc / counts)\n",
    "    with torch.no_grad():\n",
    "        running_loss, acc, counts = 0.0, 0.0, 0\n",
    "        for x, y in val_loader:\n",
    "            logits = model(x.cuda()).squeeze()\n",
    "            loss = F.cross_entropy(logits, y.cuda(), reduction='sum')\n",
    "            running_loss += loss.item()\n",
    "            acc += (logits.argmax(dim=1) == y.cuda()).float().sum()\n",
    "            counts += x.shape[0]\n",
    "        \n",
    "        print(\"val loss:\", running_loss / counts)\n",
    "        print(\"val acc:\", acc / counts)\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ef9dd4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running loss: 2.305220603942871\n",
      "running loss: 1.8644284791524657\n",
      "training acc: tensor(0.3703, device='cuda:0')\n",
      "val loss: 1.615155252456665\n",
      "val acc: tensor(0.4336, device='cuda:0')\n",
      "running loss: 1.5587794780731201\n",
      "running loss: 1.5548059872580797\n",
      "training acc: tensor(0.4559, device='cuda:0')\n",
      "val loss: 1.530853825378418\n",
      "val acc: tensor(0.4639, device='cuda:0')\n",
      "running loss: 1.5610239505767822\n",
      "running loss: 1.4520017369707332\n",
      "training acc: tensor(0.4970, device='cuda:0')\n",
      "val loss: 1.440306875038147\n",
      "val acc: tensor(0.5041, device='cuda:0')\n",
      "running loss: 1.3051495552062988\n",
      "running loss: 1.3428152725278046\n",
      "training acc: tensor(0.5306, device='cuda:0')\n",
      "val loss: 1.3976861961364746\n",
      "val acc: tensor(0.5110, device='cuda:0')\n",
      "running loss: 1.1987639665603638\n",
      "running loss: 1.265783142094532\n",
      "training acc: tensor(0.5550, device='cuda:0')\n",
      "val loss: 1.355179746246338\n",
      "val acc: tensor(0.5272, device='cuda:0')\n",
      "running loss: 1.301975131034851\n",
      "running loss: 1.2303708101177118\n",
      "training acc: tensor(0.5756, device='cuda:0')\n",
      "val loss: 1.341098497772217\n",
      "val acc: tensor(0.5341, device='cuda:0')\n",
      "running loss: 1.0301642417907715\n",
      "running loss: 1.1403395280328001\n",
      "training acc: tensor(0.6012, device='cuda:0')\n",
      "val loss: 1.344612208175659\n",
      "val acc: tensor(0.5315, device='cuda:0')\n",
      "running loss: 1.1560802459716797\n",
      "running loss: 1.1198323517361648\n",
      "training acc: tensor(0.6207, device='cuda:0')\n",
      "val loss: 1.3374215606689452\n",
      "val acc: tensor(0.5395, device='cuda:0')\n",
      "running loss: 0.9637174606323242\n",
      "running loss: 1.045134135089234\n",
      "training acc: tensor(0.6397, device='cuda:0')\n",
      "val loss: 1.3217736700057983\n",
      "val acc: tensor(0.5501, device='cuda:0')\n",
      "running loss: 0.9555442333221436\n",
      "running loss: 0.9887270565711211\n",
      "training acc: tensor(0.6612, device='cuda:0')\n",
      "val loss: 1.31807227230072\n",
      "val acc: tensor(0.5477, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "manifold = Lorentz(k=1.0)\n",
    "trainset = torchvision.datasets.CIFAR10(\"./cifar\", train=True, download=True, transform=torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(), \n",
    "    torchvision.transforms.Normalize((0.5074, 0.4867, 0.4411), (0.267, 0.256, 0.276)),\n",
    "    torchvision.transforms.Lambda(lambda x: x.view(-1))]  # Flatten to [784]\n",
    "    ))\n",
    "valset = torchvision.datasets.CIFAR10(\"./cifar\", train=False, download=True, transform=torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(), \n",
    "    torchvision.transforms.Normalize((0.5074, 0.4867, 0.4411), (0.267, 0.256, 0.276)),\n",
    "    torchvision.transforms.Lambda(lambda x: x.view(-1))]  # Flatten to [784]\n",
    "    ))\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(valset, batch_size=128, shuffle=False)\n",
    "model = LorentzMLPWithResidual(input_dim=3072, hidden_dim=512, num_classes=10, num_layers=5, manifold=manifold).cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "data, target = next(iter(train_loader))\n",
    "for _ in range(10):\n",
    "    running_loss, acc, counts = 0.0, 0.0, 0\n",
    "    for step, (x, y) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x.cuda()).squeeze()\n",
    "        loss = F.cross_entropy(logits, y.cuda())\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        if running_loss == 0.0:\n",
    "            running_loss = loss.item()\n",
    "        else:\n",
    "            running_loss = 0.99*running_loss + 0.01*loss.item()\n",
    "        acc += (logits.argmax(dim=1) == y.cuda()).float().sum()\n",
    "        counts += x.shape[0]\n",
    "        if step % 200 == 0:\n",
    "            print(\"running loss:\", running_loss)\n",
    "    print(\"training acc:\", acc / counts)\n",
    "    with torch.no_grad():\n",
    "        running_loss, acc, counts = 0.0, 0.0, 0\n",
    "        for x, y in val_loader:\n",
    "            logits = model(x.cuda()).squeeze()\n",
    "            loss = F.cross_entropy(logits, y.cuda(), reduction='sum')\n",
    "            running_loss += loss.item()\n",
    "            acc += (logits.argmax(dim=1) == y.cuda()).float().sum()\n",
    "            counts += x.shape[0]\n",
    "        \n",
    "        print(\"val loss:\", running_loss / counts)\n",
    "        print(\"val acc:\", acc / counts)\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9678d17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running loss: 2.3058390617370605\n",
      "running loss: 2.0211340024546214\n",
      "training acc: tensor(0.3046, device='cuda:0')\n",
      "val loss: 1.7915371826171875\n",
      "val acc: tensor(0.3596, device='cuda:0')\n",
      "running loss: 1.9343494176864624\n",
      "running loss: 1.7730843414496886\n",
      "training acc: tensor(0.3812, device='cuda:0')\n",
      "val loss: 1.678443069458008\n",
      "val acc: tensor(0.4012, device='cuda:0')\n",
      "running loss: 1.572021484375\n",
      "running loss: 1.6336535065898254\n",
      "training acc: tensor(0.4160, device='cuda:0')\n",
      "val loss: 1.6309209560394287\n",
      "val acc: tensor(0.4213, device='cuda:0')\n",
      "running loss: 1.557555913925171\n",
      "running loss: 1.5806652708439088\n",
      "training acc: tensor(0.4370, device='cuda:0')\n",
      "val loss: 1.597140937614441\n",
      "val acc: tensor(0.4342, device='cuda:0')\n",
      "running loss: 1.4735374450683594\n",
      "running loss: 1.5395157643996717\n",
      "training acc: tensor(0.4512, device='cuda:0')\n",
      "val loss: 1.5782439380645752\n",
      "val acc: tensor(0.4410, device='cuda:0')\n",
      "running loss: 1.6799933910369873\n",
      "running loss: 1.544618162205239\n",
      "training acc: tensor(0.4625, device='cuda:0')\n",
      "val loss: 1.5606171977996826\n",
      "val acc: tensor(0.4468, device='cuda:0')\n",
      "running loss: 1.5422781705856323\n",
      "running loss: 1.5030143617898526\n",
      "training acc: tensor(0.4743, device='cuda:0')\n",
      "val loss: 1.5500567199707032\n",
      "val acc: tensor(0.4498, device='cuda:0')\n",
      "running loss: 1.3791875839233398\n",
      "running loss: 1.459880473088536\n",
      "training acc: tensor(0.4795, device='cuda:0')\n",
      "val loss: 1.5374985610961913\n",
      "val acc: tensor(0.4533, device='cuda:0')\n",
      "running loss: 1.4937821626663208\n",
      "running loss: 1.4541511967132972\n",
      "training acc: tensor(0.4876, device='cuda:0')\n",
      "val loss: 1.5219520511627198\n",
      "val acc: tensor(0.4625, device='cuda:0')\n",
      "running loss: 1.4648964405059814\n",
      "running loss: 1.4382920277783517\n",
      "training acc: tensor(0.4934, device='cuda:0')\n",
      "val loss: 1.5286873657226563\n",
      "val acc: tensor(0.4587, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "manifold = Lorentz(k=1.0)\n",
    "trainset = torchvision.datasets.CIFAR10(\"./cifar\", train=True, download=True, transform=torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(), \n",
    "    torchvision.transforms.Normalize((0.5074, 0.4867, 0.4411), (0.267, 0.256, 0.276)),\n",
    "    torchvision.transforms.Lambda(lambda x: x.view(-1))]  # Flatten to [784]\n",
    "    ))\n",
    "valset = torchvision.datasets.CIFAR10(\"./cifar\", train=False, download=True, transform=torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(), \n",
    "    torchvision.transforms.Normalize((0.5074, 0.4867, 0.4411), (0.267, 0.256, 0.276)),\n",
    "    torchvision.transforms.Lambda(lambda x: x.view(-1))]  # Flatten to [784]\n",
    "    ))\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(valset, batch_size=128, shuffle=False)\n",
    "model = LorentzMLPWithResidual(input_dim=3072, hidden_dim=32, num_classes=10, num_layers=5, manifold=manifold).cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "data, target = next(iter(train_loader))\n",
    "for _ in range(10):\n",
    "    running_loss, acc, counts = 0.0, 0.0, 0\n",
    "    for step, (x, y) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x.cuda()).squeeze()\n",
    "        loss = F.cross_entropy(logits, y.cuda())\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        if running_loss == 0.0:\n",
    "            running_loss = loss.item()\n",
    "        else:\n",
    "            running_loss = 0.99*running_loss + 0.01*loss.item()\n",
    "        acc += (logits.argmax(dim=1) == y.cuda()).float().sum()\n",
    "        counts += x.shape[0]\n",
    "        if step % 200 == 0:\n",
    "            print(\"running loss:\", running_loss)\n",
    "    print(\"training acc:\", acc / counts)\n",
    "    with torch.no_grad():\n",
    "        running_loss, acc, counts = 0.0, 0.0, 0\n",
    "        for x, y in val_loader:\n",
    "            logits = model(x.cuda()).squeeze()\n",
    "            loss = F.cross_entropy(logits, y.cuda(), reduction='sum')\n",
    "            running_loss += loss.item()\n",
    "            acc += (logits.argmax(dim=1) == y.cuda()).float().sum()\n",
    "            counts += x.shape[0]\n",
    "        \n",
    "        print(\"val loss:\", running_loss / counts)\n",
    "        print(\"val acc:\", acc / counts)\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e64e35ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running loss: 2.302795886993408\n",
      "running loss: 2.0442883380780663\n",
      "training acc: tensor(0.2520, device='cuda:0')\n",
      "val loss: 1.8573101421356202\n",
      "val acc: tensor(0.2844, device='cuda:0')\n",
      "running loss: 1.932027816772461\n",
      "running loss: 1.8325329554424292\n",
      "training acc: tensor(0.3269, device='cuda:0')\n",
      "val loss: 1.708279984664917\n",
      "val acc: tensor(0.3707, device='cuda:0')\n",
      "running loss: 1.7115061283111572\n",
      "running loss: 1.6660110259129737\n",
      "training acc: tensor(0.4009, device='cuda:0')\n",
      "val loss: 1.6019438676834106\n",
      "val acc: tensor(0.4154, device='cuda:0')\n",
      "running loss: 1.6104451417922974\n",
      "running loss: 1.5641192649609441\n",
      "training acc: tensor(0.4405, device='cuda:0')\n",
      "val loss: 1.5702522071838378\n",
      "val acc: tensor(0.4346, device='cuda:0')\n",
      "running loss: 1.646928310394287\n",
      "running loss: 1.5112884959712634\n",
      "training acc: tensor(0.4695, device='cuda:0')\n",
      "val loss: 1.509370757675171\n",
      "val acc: tensor(0.4672, device='cuda:0')\n",
      "running loss: 1.2755305767059326\n",
      "running loss: 1.41075922000999\n",
      "training acc: tensor(0.4980, device='cuda:0')\n",
      "val loss: 1.5046340885162353\n",
      "val acc: tensor(0.4631, device='cuda:0')\n",
      "running loss: 1.200024127960205\n",
      "running loss: 1.3354259928290555\n",
      "training acc: tensor(0.5241, device='cuda:0')\n",
      "val loss: 1.4692036338806151\n",
      "val acc: tensor(0.4812, device='cuda:0')\n",
      "running loss: 1.1682144403457642\n",
      "running loss: 1.2863415838025798\n",
      "training acc: tensor(0.5517, device='cuda:0')\n",
      "val loss: 1.4568299236297608\n",
      "val acc: tensor(0.4949, device='cuda:0')\n",
      "running loss: 1.1056714057922363\n",
      "running loss: 1.2010055324839441\n",
      "training acc: tensor(0.5722, device='cuda:0')\n",
      "val loss: 1.4280422151565553\n",
      "val acc: tensor(0.5052, device='cuda:0')\n",
      "running loss: 0.9773848056793213\n",
      "running loss: 1.1463926013997838\n",
      "training acc: tensor(0.5918, device='cuda:0')\n",
      "val loss: 1.4010574464797974\n",
      "val acc: tensor(0.5173, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "manifold = Lorentz(k=1.0)\n",
    "trainset = torchvision.datasets.CIFAR10(\"./cifar\", train=True, download=True, transform=torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(), \n",
    "    torchvision.transforms.Normalize((0.5074, 0.4867, 0.4411), (0.267, 0.256, 0.276)),\n",
    "    torchvision.transforms.Lambda(lambda x: x.view(-1))]  # Flatten to [784]\n",
    "    ))\n",
    "valset = torchvision.datasets.CIFAR10(\"./cifar\", train=False, download=True, transform=torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(), \n",
    "    torchvision.transforms.Normalize((0.5074, 0.4867, 0.4411), (0.267, 0.256, 0.276)),\n",
    "    torchvision.transforms.Lambda(lambda x: x.view(-1))]  # Flatten to [784]\n",
    "    ))\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(valset, batch_size=128, shuffle=False)\n",
    "model = LorentzMLPWithResidual(input_dim=3072, hidden_dim=512, num_classes=10, num_layers=10, manifold=manifold).cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "data, target = next(iter(train_loader))\n",
    "for _ in range(10):\n",
    "    running_loss, acc, counts = 0.0, 0.0, 0\n",
    "    for step, (x, y) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x.cuda()).squeeze()\n",
    "        loss = F.cross_entropy(logits, y.cuda())\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        if running_loss == 0.0:\n",
    "            running_loss = loss.item()\n",
    "        else:\n",
    "            running_loss = 0.99*running_loss + 0.01*loss.item()\n",
    "        acc += (logits.argmax(dim=1) == y.cuda()).float().sum()\n",
    "        counts += x.shape[0]\n",
    "        if step % 200 == 0:\n",
    "            print(\"running loss:\", running_loss)\n",
    "    print(\"training acc:\", acc / counts)\n",
    "    with torch.no_grad():\n",
    "        running_loss, acc, counts = 0.0, 0.0, 0\n",
    "        for x, y in val_loader:\n",
    "            logits = model(x.cuda()).squeeze()\n",
    "            loss = F.cross_entropy(logits, y.cuda(), reduction='sum')\n",
    "            running_loss += loss.item()\n",
    "            acc += (logits.argmax(dim=1) == y.cuda()).float().sum()\n",
    "            counts += x.shape[0]\n",
    "        \n",
    "        print(\"val loss:\", running_loss / counts)\n",
    "        print(\"val acc:\", acc / counts)\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb5f9ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([96, 90, 14, 77, 65,  7, 75, 27, 16, 30, 50, 83, 14, 51, 42, 70])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manifold = Lorentz(k=1.0)\n",
    "trainset = torchvision.datasets.CIFAR10(\"./cifar\", train=True, download=True, transform=torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(), \n",
    "    torchvision.transforms.Normalize((0.5074, 0.4867, 0.4411), (0.267, 0.256, 0.276)),\n",
    "    torchvision.transforms.Lambda(lambda x: x.view(-1))]  # Flatten to [784]\n",
    "    ))\n",
    "valset = torchvision.datasets.CIFAR10(\"./cifar\", train=False, download=True, transform=torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(), \n",
    "    torchvision.transforms.Normalize((0.5074, 0.4867, 0.4411), (0.267, 0.256, 0.276)),\n",
    "    torchvision.transforms.Lambda(lambda x: x.view(-1))]  # Flatten to [784]\n",
    "    ))\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(valset, batch_size=128, shuffle=False)\n",
    "model = LorentzMLPWithResidual(input_dim=3072, hidden_dim=512, num_classes=10, num_layers=10, manifold=manifold).cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "data, target = next(iter(train_loader))\n",
    "for _ in range(10):\n",
    "    running_loss, acc, counts = 0.0, 0.0, 0\n",
    "    for step, (x, y) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x.cuda()).squeeze()\n",
    "        loss = F.cross_entropy(logits, y.cuda())\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        if running_loss == 0.0:\n",
    "            running_loss = loss.item()\n",
    "        else:\n",
    "            running_loss = 0.99*running_loss + 0.01*loss.item()\n",
    "        acc += (logits.argmax(dim=1) == y.cuda()).float().sum()\n",
    "        counts += x.shape[0]\n",
    "        if step % 200 == 0:\n",
    "            print(\"running loss:\", running_loss)\n",
    "    print(\"training acc:\", acc / counts)\n",
    "    with torch.no_grad():\n",
    "        running_loss, acc, counts = 0.0, 0.0, 0\n",
    "        for x, y in val_loader:\n",
    "            logits = model(x.cuda()).squeeze()\n",
    "            loss = F.cross_entropy(logits, y.cuda(), reduction='sum')\n",
    "            running_loss += loss.item()\n",
    "            acc += (logits.argmax(dim=1) == y.cuda()).float().sum()\n",
    "            counts += x.shape[0]\n",
    "        \n",
    "        print(\"val loss:\", running_loss / counts)\n",
    "        print(\"val acc:\", acc / counts)\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a55d73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71e12230",
   "metadata": {},
   "source": [
    "# NEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "cb5a6733",
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers import Lorentz_fully_connected\n",
    "from layers import Lorentz\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "\n",
    "\n",
    "class EuclideanToLorentzConv(nn.Module):\n",
    "    \"\"\"Project Euclidean image onto Lorentz manifold via 1x1 conv.\"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, manifold):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_channels: Euclidean channels (e.g., 3 for RGB)\n",
    "            out_channels: Lorentz channels INCLUDING time (e.g., 16 means 15 space + 1 time)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.manifold = manifold\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels - 1, kernel_size=1)\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.conv.weight, gain=0.1)\n",
    "        nn.init.zeros_(self.conv.bias)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: [batch, in_channels, H, W] Euclidean image\n",
    "        Returns:\n",
    "            [batch, out_channels, H, W] on Lorentz manifold (each pixel is a Lorentz point)\n",
    "        \"\"\"\n",
    "        space = self.conv(x)  # [batch, out_channels - 1, H, W]\n",
    "        \n",
    "        # Compute time component for each pixel\n",
    "        # time = sqrt(||space||^2 + 1/k)\n",
    "        time = torch.sqrt((space ** 2).sum(dim=1, keepdim=True) + 1.0 / self.manifold.k())\n",
    "        \n",
    "        return torch.cat([time, space], dim=1)  # [batch, out_channels, H, W]\n",
    "\n",
    "class LorentzResidualMidpoint(nn.Module):\n",
    "    \"\"\"Residual via weighted Lorentz midpoint.\"\"\"\n",
    "    \n",
    "    def __init__(self, dim, manifold, activation):\n",
    "        super().__init__()\n",
    "        self.manifold = manifold\n",
    "        self.fc = Lorentz_fully_connected(\n",
    "            in_features=dim,\n",
    "            out_features=dim,\n",
    "            manifold=manifold,\n",
    "            reset_params=\"kaiming\",\n",
    "            activation=activation\n",
    "        )\n",
    "        # Learnable weight (0.5 = equal weighting)\n",
    "        self.alpha_logit = nn.Parameter(torch.tensor(0.0))  # sigmoid(0) = 0.5\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc(x)\n",
    "        \n",
    "        # Weighted midpoint on manifold\n",
    "        alpha = torch.sigmoid(self.alpha_logit)\n",
    "        # Stack for centroid computation: [batch, 2, dim]\n",
    "        stacked = torch.stack([x, out], dim=-2)\n",
    "        \n",
    "        # Weights: [1, 2] -> broadcast to [batch, 2]\n",
    "        weights = torch.tensor([[1 - alpha, alpha]], device=x.device)\n",
    "        return self.manifold.lorentz_midpoint(stacked, weights)\n",
    "    \n",
    "\n",
    "class LorentzConv2d(nn.Module):\n",
    "    \"\"\"\n",
    "    Lorentz Conv2d using direct concatenation + existing Lorentz FC.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        kernel_size: int | tuple[int, int],\n",
    "        stride: int | tuple[int, int],\n",
    "        padding: int | tuple[int, int],\n",
    "        manifold: Lorentz,\n",
    "        activation,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.manifold = manifold or Lorentz(k=1.0)\n",
    "        \n",
    "        if isinstance(kernel_size, int):\n",
    "            kernel_size = (kernel_size, kernel_size)\n",
    "        if isinstance(stride, int):\n",
    "            stride = (stride, stride)\n",
    "        if isinstance(padding, int):\n",
    "            padding = (padding, padding)\n",
    "        \n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        \n",
    "        # After concatenating k*k Lorentz points:\n",
    "        # concat_dim = 1 + (in_channels - 1) * k * k\n",
    "        concat_dim = 1 + (in_channels - 1) * kernel_size[0] * kernel_size[1]\n",
    "        \n",
    "        # Reuse existing Lorentz FC\n",
    "        self.fc = Lorentz_fully_connected(\n",
    "            in_features=concat_dim,\n",
    "            out_features=out_channels,\n",
    "            manifold=self.manifold,\n",
    "            activation=activation,\n",
    "            reset_params=\"kaiming\"\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: [batch, in_channels, H, W]\n",
    "        Returns:\n",
    "            [batch, out_channels, H', W']\n",
    "        \"\"\"\n",
    "        batch, C, H, W = x.shape\n",
    "        kH, kW = self.kernel_size\n",
    "        sH, sW = self.stride\n",
    "        pH, pW = self.padding\n",
    "        \n",
    "        # Pad with origin points\n",
    "        if pH > 0 or pW > 0:\n",
    "            sqrt_k_inv = (1.0 / self.manifold.k()).sqrt()\n",
    "            x = F.pad(x, (pW, pW, pH, pH), mode='constant', value=0.0)\n",
    "            _, _, H_pad, W_pad = x.shape\n",
    "            \n",
    "            # Fix time component in padded regions\n",
    "            mask = torch.ones(1, 1, H_pad, W_pad, device=x.device, dtype=x.dtype)\n",
    "            mask[:, :, pH:pH+H, pW:pW+W] = 0\n",
    "            x[:, 0:1] = x[:, 0:1] * (1 - mask) + sqrt_k_inv * mask\n",
    "        \n",
    "        # Unfold: [batch, C * kH * kW, num_patches]\n",
    "        patches = F.unfold(x, kernel_size=self.kernel_size, stride=self.stride)\n",
    "        \n",
    "        # Reshape to [batch, num_patches, kH * kW, C]\n",
    "        num_patches = patches.shape[-1]\n",
    "        patches = patches.view(batch, C, kH * kW, num_patches)\n",
    "        patches = patches.permute(0, 3, 2, 1)  # [batch, num_patches, k*k, C]\n",
    "        \n",
    "        # Direct concat: [batch * num_patches, k*k, C] -> [batch * num_patches, concat_dim]\n",
    "        patches_flat = patches.reshape(batch * num_patches, kH * kW, C)\n",
    "        concat_points = self.manifold.direct_concat(patches_flat)\n",
    "        \n",
    "        # Apply Lorentz FC: [batch * num_patches, concat_dim] -> [batch * num_patches, out_channels]\n",
    "        out = self.fc(concat_points)\n",
    "        \n",
    "        # Reshape to spatial: [batch, out_channels, H', W']\n",
    "        H_out = (H + 2 * pH - kH) // sH + 1\n",
    "        W_out = (W + 2 * pW - kW) // sW + 1\n",
    "        out = out.view(batch, H_out, W_out, -1).permute(0, 3, 1, 2)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class LorentzResBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        input_dim,\n",
    "        output_dim,\n",
    "        kernel_size,\n",
    "        stride,\n",
    "        padding,\n",
    "        manifold,\n",
    "        activation,\n",
    "    ):\n",
    "    \n",
    "        super().__init__()\n",
    "        self.manifold = manifold or Lorentz(k=1.0)\n",
    "\n",
    "        self.layer1 = LorentzConv2d(in_channels=input_dim, out_channels=input_dim, kernel_size=kernel_size, stride=1, padding=padding, manifold=manifold, activation=activation)\n",
    "        self.bn1 = LorentzBatchNorm2d(num_features = input_dim, manifold=manifold)\n",
    "        self.layer2 = LorentzConv2d(in_channels=input_dim, out_channels=output_dim, kernel_size=kernel_size, stride=stride, padding=padding, manifold=manifold, activation=nn.Identity())\n",
    "        self.bn2 = LorentzBatchNorm2d(num_features = output_dim, manifold=manifold)\n",
    "        if input_dim != output_dim:\n",
    "            self.proj = LorentzConv2d(in_channels=input_dim, out_channels=output_dim, kernel_size=1, stride=stride, padding=0, manifold=manifold, activation=nn.Identity())\n",
    "        else:\n",
    "            self.proj = nn.Identity()\n",
    "\n",
    "        self.alpha_logit = nn.Parameter(torch.tensor(0.0))  # sigmoid(0) = 0.5\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x2 = self.layer1(x)\n",
    "        x2 = self.bn1(x2)\n",
    "        x2 = self.layer2(x2)\n",
    "        x2 = self.bn2(x2)\n",
    "        x = self.proj(x)\n",
    "\n",
    "\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        x2 = x2.permute(0, 2, 3, 1)\n",
    "        stacked = torch.stack([x, x2], dim=-2)\n",
    "        alpha = torch.sigmoid(self.alpha_logit)\n",
    "        weights = torch.stack([1-alpha, alpha])\n",
    "        x = self.manifold.lorentz_midpoint(stacked, weights)\n",
    "\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "\n",
    "        return x\n",
    "\n",
    "class LorentzConvNet(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        input_dim,\n",
    "        hidden_dim,\n",
    "        num_classes,\n",
    "        num_layers,\n",
    "        manifold,\n",
    "        activation\n",
    "    ):\n",
    "    \n",
    "        super().__init__()\n",
    "        self.manifold = manifold or Lorentz(k=1.0)\n",
    "        \n",
    "        # Input projection\n",
    "        self.input_proj = EuclideanToLorentzConv(input_dim, hidden_dim, self.manifold)       \n",
    "\n",
    "        self.resblock1 = LorentzResBlock(input_dim=hidden_dim, output_dim=hidden_dim*2, kernel_size=3, stride=2, padding=1, manifold=manifold, activation=activation)\n",
    "        self.resblock2 = LorentzResBlock(input_dim=hidden_dim*2, output_dim=hidden_dim*4, kernel_size=3, stride=2, padding=1, manifold=manifold, activation=activation)\n",
    "        self.resblock3 = LorentzResBlock(input_dim=hidden_dim*4, output_dim=hidden_dim*8, kernel_size=3, stride=2, padding=1, manifold=manifold, activation=activation)\n",
    "        self.resblock4 = LorentzResBlock(input_dim=hidden_dim*8, output_dim=hidden_dim*16, kernel_size=3, stride=2, padding=1, manifold=manifold, activation=activation)\n",
    "        self.resblock5 = LorentzResBlock(input_dim=hidden_dim*16, output_dim=hidden_dim*32, kernel_size=3, stride=2, padding=1, manifold=manifold, activation=activation)\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = Lorentz_fully_connected(\n",
    "            in_features=hidden_dim*32,\n",
    "            out_features=num_classes + 1,\n",
    "            manifold=self.manifold,\n",
    "            reset_params=\"kaiming\",\n",
    "            do_mlr=True\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.input_proj(x)\n",
    "        # print(x[0, :, 0, 0])\n",
    "        x = self.resblock1(x)\n",
    "        # print(x[0, :, 0, 0])\n",
    "        x = self.resblock2(x)\n",
    "        x = self.resblock3(x)\n",
    "        x = self.resblock4(x)\n",
    "        x = self.resblock5(x)\n",
    "\n",
    "        x = x.squeeze(-1).squeeze(-1)\n",
    "        if len(x.shape) == 2:\n",
    "            return self.classifier(x)\n",
    "        else:\n",
    "            x = x.view(x.shape[0], x.shape[1], -1)\n",
    "            x = x.permute(0, 2, 1)\n",
    "            x = self.manifold.lorentz_midpoint(x)\n",
    "            return self.classifier(x)\n",
    "\n",
    "class LorentzBatchNorm2d(nn.Module):\n",
    "    \"\"\"\n",
    "    Lorentz Batch Normalization following Bdeir et al.\n",
    "    Simplified to use manifold primitives.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        num_features: int,\n",
    "        manifold: Lorentz = None,\n",
    "        momentum: float = 0.1,\n",
    "        eps: float = 1e-5,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.manifold = manifold or Lorentz(k=1.0)\n",
    "        self.num_features = num_features\n",
    "        self.momentum = momentum\n",
    "        self.eps = eps\n",
    "        \n",
    "        # Learnable scale (positive real)\n",
    "        self.gamma = nn.Parameter(torch.ones(1, num_features - 1, 1, 1))\n",
    "        \n",
    "        # Learnable shift (space components, will be projected to manifold)\n",
    "        self.beta_space = nn.Parameter(torch.zeros(1, num_features - 1, 1, 1))\n",
    "        \n",
    "        # Running statistics (store space components of centroid)\n",
    "        self.register_buffer('running_mean_space', torch.zeros(1, num_features - 1, 1, 1))\n",
    "        self.register_buffer('running_var', torch.ones(1))\n",
    "    \n",
    "    def _to_flat(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"[B, C, H, W] -> [B*H*W, C]\"\"\"\n",
    "        return x.permute(0, 2, 3, 1).reshape(-1, x.shape[1])\n",
    "    \n",
    "    def _to_spatial(self, x_flat: torch.Tensor, batch: int, H: int, W: int) -> torch.Tensor:\n",
    "        \"\"\"[B*H*W, C] -> [B, C, H, W]\"\"\"\n",
    "        return x_flat.view(batch, H, W, -1).permute(0, 3, 1, 2)\n",
    "    \n",
    "    def _compute_centroid(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Compute Lorentz centroid using manifold method.\"\"\"\n",
    "        batch, C, H, W = x.shape\n",
    "        x_flat = self._to_flat(x)  # [N, C]\n",
    "        \n",
    "        # lorentz_midpoint expects [..., num_points, dim]\n",
    "        # We want centroid over all N points, so reshape to [1, N, C]\n",
    "        centroid = self.manifold.lorentz_midpoint(x_flat.unsqueeze(0))  # [1, C]\n",
    "        \n",
    "        return centroid.view(1, C, 1, 1)\n",
    "    \n",
    "    def _compute_variance(self, x: torch.Tensor, mean: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Compute Frchet variance (mean squared geodesic distance).\"\"\"\n",
    "        batch, C, H, W = x.shape\n",
    "        x_flat = self._to_flat(x)  # [N, C]\n",
    "        mean_flat = mean.view(1, C).expand(x_flat.shape[0], -1)  # [N, C]\n",
    "        \n",
    "        # Use manifold distance\n",
    "        dist_sq = self.manifold.dist(x_flat, mean_flat, keepdim=False) ** 2\n",
    "        return dist_sq.mean()\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        batch, C, H, W = x.shape\n",
    "        \n",
    "        if self.training:\n",
    "            mean = self._compute_centroid(x)\n",
    "            var = self._compute_variance(x, mean)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                self.running_mean_space.mul_(1 - self.momentum).add_(\n",
    "                    mean[:, 1:, :, :] * self.momentum\n",
    "                )\n",
    "                self.running_var.mul_(1 - self.momentum).add_(var * self.momentum)\n",
    "        else:\n",
    "            # Reconstruct mean from running space components\n",
    "            mean_space_flat = self.running_mean_space.view(1, -1)  # [1, C-1]\n",
    "            mean_flat = self.manifold.projection_space_orthogonal(mean_space_flat)  # [1, C]\n",
    "            mean = mean_flat.view(1, C, 1, 1)\n",
    "            var = self.running_var\n",
    "        \n",
    "        # Flatten for manifold operations\n",
    "        x_flat = self._to_flat(x)  # [N, C]\n",
    "        mean_flat = mean.view(1, C).expand(x_flat.shape[0], -1)\n",
    "        \n",
    "        # Origin point\n",
    "        origin = self.manifold.origin(C).unsqueeze(0).expand(x_flat.shape[0], -1)\n",
    "        \n",
    "        # 1. Log map: get tangent vector at mean pointing to x\n",
    "        # logmap expects [batch, dim] for base and [batch, m, dim] for target\n",
    "        v_at_mean = self.manifold.logmap(mean_flat, x_flat.unsqueeze(1)).squeeze(1)  # [N, C]\n",
    "        \n",
    "        # 2. Parallel transport tangent vector from mean to origin\n",
    "        v_at_origin = self.manifold.parallel_transport(mean_flat, v_at_mean.unsqueeze(1), origin).squeeze(1)\n",
    "        \n",
    "        # 3. Scale in tangent space (only space components, time should stay ~0)\n",
    "        # Tangent vectors at origin have time  0\n",
    "        v_space = v_at_origin[:, 1:]  # [N, C-1]\n",
    "        gamma_flat = self.gamma.view(1, -1)  # [1, C-1]\n",
    "        v_scaled_space = gamma_flat * v_space / (var.sqrt() + self.eps)\n",
    "        \n",
    "        # 4. Add shift (beta)\n",
    "        beta_flat = self.beta_space.view(1, -1)  # [1, C-1]\n",
    "        v_shifted_space = v_scaled_space + beta_flat\n",
    "        \n",
    "        # 5. Project back to manifold from space components\n",
    "        x_out_flat = self.manifold.projection_space_orthogonal(v_shifted_space)\n",
    "        \n",
    "        return self._to_spatial(x_out_flat, batch, H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db5d0c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers import LorentzConvNet\n",
    "from layers import Lorentz\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a83030ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0090,  0.0173, -0.0277,  0.0192, -0.0033,  0.0283, -0.0026, -0.0180,\n",
       "         -0.0009,  0.0043,  0.0032, -0.0098, -0.0289, -0.0091, -0.0326]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.resblock1.layer1.fc.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6caa17b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running loss: 4.613415718078613\n",
      "running loss: 4.109422631907814\n",
      "training acc: tensor(0.0930, device='cuda:0')\n",
      "val loss: 3.6462308765411375\n",
      "val acc: tensor(0.1336, device='cuda:0')\n",
      "running loss: 3.6820125579833984\n",
      "running loss: 3.5163753930030177\n",
      "training acc: tensor(0.1701, device='cuda:0')\n",
      "val loss: 3.270312439727783\n",
      "val acc: tensor(0.2078, device='cuda:0')\n",
      "running loss: 3.1570048332214355\n",
      "running loss: 3.164134492874118\n",
      "training acc: tensor(0.2300, device='cuda:0')\n",
      "val loss: 3.1041206703186037\n",
      "val acc: tensor(0.2369, device='cuda:0')\n",
      "running loss: 2.9298155307769775\n",
      "running loss: 2.9147103132115295\n",
      "training acc: tensor(0.2700, device='cuda:0')\n",
      "val loss: 2.9680451629638673\n",
      "val acc: tensor(0.2616, device='cuda:0')\n",
      "running loss: 2.683765411376953\n",
      "running loss: 2.7043033775335155\n",
      "training acc: tensor(0.3152, device='cuda:0')\n",
      "val loss: 2.83157795791626\n",
      "val acc: tensor(0.2951, device='cuda:0')\n",
      "running loss: 2.8003339767456055\n",
      "running loss: 2.545985702709308\n",
      "training acc: tensor(0.3519, device='cuda:0')\n",
      "val loss: 2.74352776260376\n",
      "val acc: tensor(0.3228, device='cuda:0')\n",
      "running loss: 2.159778118133545\n",
      "running loss: 2.331882097382524\n",
      "training acc: tensor(0.3882, device='cuda:0')\n",
      "val loss: 2.740280599975586\n",
      "val acc: tensor(0.3198, device='cuda:0')\n",
      "running loss: 2.3889875411987305\n",
      "running loss: 2.2358485368559418\n",
      "training acc: tensor(0.4144, device='cuda:0')\n",
      "val loss: 2.695375162887573\n",
      "val acc: tensor(0.3362, device='cuda:0')\n",
      "running loss: 2.27858829498291\n",
      "running loss: 2.113547584917284\n",
      "training acc: tensor(0.4439, device='cuda:0')\n",
      "val loss: 2.675612338256836\n",
      "val acc: tensor(0.3408, device='cuda:0')\n",
      "running loss: 1.8312621116638184\n",
      "running loss: 1.9493339871539412\n",
      "training acc: tensor(0.4716, device='cuda:0')\n",
      "val loss: 2.7063284675598145\n",
      "val acc: tensor(0.3461, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "manifold = Lorentz(k=1.0)\n",
    "trainset = torchvision.datasets.CIFAR100(\"./cifar\", train=True, download=True, transform=torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(), \n",
    "    torchvision.transforms.Normalize((0.5074, 0.4867, 0.4411), (0.267, 0.256, 0.276))]\n",
    "    ))\n",
    "valset = torchvision.datasets.CIFAR100(\"./cifar\", train=False, download=True, transform=torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(), \n",
    "    torchvision.transforms.Normalize((0.5074, 0.4867, 0.4411), (0.267, 0.256, 0.276)),]\n",
    "    ))\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(valset, batch_size=128, shuffle=False)\n",
    "model = LorentzConvNet(input_dim=3, hidden_dim=16, num_classes=100, num_layers=5, manifold=manifold, activation=nn.ReLU()).cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "data, target = next(iter(train_loader))\n",
    "for _ in range(10):\n",
    "    running_loss, acc, counts = 0.0, 0.0, 0\n",
    "    for step, (x, y) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x.cuda()).squeeze()\n",
    "        loss = F.cross_entropy(logits, y.cuda())\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        if running_loss == 0.0:\n",
    "            running_loss = loss.item()\n",
    "        else:\n",
    "            running_loss = 0.99*running_loss + 0.01*loss.item()\n",
    "        acc += (logits.argmax(dim=1) == y.cuda()).float().sum()\n",
    "        counts += x.shape[0]\n",
    "        if step % 200 == 0:\n",
    "            print(\"running loss:\", running_loss)\n",
    "    print(\"training acc:\", acc / counts)\n",
    "    with torch.no_grad():\n",
    "        running_loss, acc, counts = 0.0, 0.0, 0\n",
    "        for x, y in val_loader:\n",
    "            logits = model(x.cuda()).squeeze()\n",
    "            loss = F.cross_entropy(logits, y.cuda(), reduction='sum')\n",
    "            running_loss += loss.item()\n",
    "            acc += (logits.argmax(dim=1) == y.cuda()).float().sum()\n",
    "            counts += x.shape[0]\n",
    "        \n",
    "        print(\"val loss:\", running_loss / counts)\n",
    "        print(\"val acc:\", acc / counts)\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4dfad26d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor(-1.8509, device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.resblock5.alpha_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "17825939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running loss: 4.60404634475708\n",
      "running loss: 4.133440152762814\n",
      "training acc: tensor(0.0987, device='cuda:0')\n",
      "val loss: 3.6226573753356934\n",
      "val acc: tensor(0.1476, device='cuda:0')\n",
      "running loss: 3.6821200847625732\n",
      "running loss: 3.5466236492681404\n",
      "training acc: tensor(0.1664, device='cuda:0')\n",
      "val loss: 3.3628051738739013\n",
      "val acc: tensor(0.1944, device='cuda:0')\n",
      "running loss: 3.363978862762451\n",
      "running loss: 3.2429910072192207\n",
      "training acc: tensor(0.2195, device='cuda:0')\n",
      "val loss: 3.142463459777832\n",
      "val acc: tensor(0.2352, device='cuda:0')\n",
      "running loss: 2.9758212566375732\n",
      "running loss: 2.97109549545084\n",
      "training acc: tensor(0.2640, device='cuda:0')\n",
      "val loss: 2.988465799713135\n",
      "val acc: tensor(0.2667, device='cuda:0')\n",
      "running loss: 2.5802388191223145\n",
      "running loss: 2.7540598730182064\n",
      "training acc: tensor(0.3055, device='cuda:0')\n",
      "val loss: 2.858040071105957\n",
      "val acc: tensor(0.2932, device='cuda:0')\n",
      "running loss: 2.7477383613586426\n",
      "running loss: 2.5997239111926818\n",
      "training acc: tensor(0.3400, device='cuda:0')\n",
      "val loss: 2.7804719440460204\n",
      "val acc: tensor(0.3122, device='cuda:0')\n",
      "running loss: 2.3071250915527344\n",
      "running loss: 2.40605732568592\n",
      "training acc: tensor(0.3753, device='cuda:0')\n",
      "val loss: 2.7416432361602783\n",
      "val acc: tensor(0.3145, device='cuda:0')\n",
      "running loss: 2.3649063110351562\n",
      "running loss: 2.274004360924625\n",
      "training acc: tensor(0.4079, device='cuda:0')\n",
      "val loss: 2.7028679916381835\n",
      "val acc: tensor(0.3232, device='cuda:0')\n",
      "running loss: 1.8669822216033936\n",
      "running loss: 2.103406356624522\n",
      "training acc: tensor(0.4336, device='cuda:0')\n",
      "val loss: 2.696473222351074\n",
      "val acc: tensor(0.3295, device='cuda:0')\n",
      "running loss: 2.07639741897583\n",
      "running loss: 2.0310557722595215\n",
      "training acc: tensor(0.4603, device='cuda:0')\n",
      "val loss: 2.6949321319580077\n",
      "val acc: tensor(0.3380, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "manifold = Lorentz(k=1.0)\n",
    "trainset = torchvision.datasets.CIFAR100(\"./cifar\", train=True, download=True, transform=torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(), \n",
    "    torchvision.transforms.Normalize((0.5074, 0.4867, 0.4411), (0.267, 0.256, 0.276))]\n",
    "    ))\n",
    "valset = torchvision.datasets.CIFAR100(\"./cifar\", train=False, download=True, transform=torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(), \n",
    "    torchvision.transforms.Normalize((0.5074, 0.4867, 0.4411), (0.267, 0.256, 0.276)),]\n",
    "    ))\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(valset, batch_size=128, shuffle=False)\n",
    "model = LorentzConvNet(input_dim=3, hidden_dim=16, num_classes=100, num_layers=5, manifold=manifold, activation=nn.ReLU()).cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "data, target = next(iter(train_loader))\n",
    "for _ in range(10):\n",
    "    running_loss, acc, counts = 0.0, 0.0, 0\n",
    "    for step, (x, y) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x.cuda()).squeeze()\n",
    "        loss = F.cross_entropy(logits, y.cuda())\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        if running_loss == 0.0:\n",
    "            running_loss = loss.item()\n",
    "        else:\n",
    "            running_loss = 0.99*running_loss + 0.01*loss.item()\n",
    "        acc += (logits.argmax(dim=1) == y.cuda()).float().sum()\n",
    "        counts += x.shape[0]\n",
    "        if step % 200 == 0:\n",
    "            print(\"running loss:\", running_loss)\n",
    "    print(\"training acc:\", acc / counts)\n",
    "    with torch.no_grad():\n",
    "        running_loss, acc, counts = 0.0, 0.0, 0\n",
    "        for x, y in val_loader:\n",
    "            logits = model(x.cuda()).squeeze()\n",
    "            loss = F.cross_entropy(logits, y.cuda(), reduction='sum')\n",
    "            running_loss += loss.item()\n",
    "            acc += (logits.argmax(dim=1) == y.cuda()).float().sum()\n",
    "            counts += x.shape[0]\n",
    "        \n",
    "        print(\"val loss:\", running_loss / counts)\n",
    "        print(\"val acc:\", acc / counts)\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c4cbb40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running loss: 4.614555358886719\n",
      "running loss: 4.178154148873151\n",
      "training acc: tensor(0.0845, device='cuda:0')\n",
      "val loss: 3.6940881423950196\n",
      "val acc: tensor(0.1257, device='cuda:0')\n",
      "running loss: 3.7043490409851074\n",
      "running loss: 3.5906297556455886\n",
      "training acc: tensor(0.1536, device='cuda:0')\n",
      "val loss: 3.441946120071411\n",
      "val acc: tensor(0.1725, device='cuda:0')\n",
      "running loss: 3.2883236408233643\n",
      "running loss: 3.2957802840544117\n",
      "training acc: tensor(0.2022, device='cuda:0')\n",
      "val loss: 3.221691360473633\n",
      "val acc: tensor(0.2182, device='cuda:0')\n",
      "running loss: 3.1265478134155273\n",
      "running loss: 3.083497251221289\n",
      "training acc: tensor(0.2475, device='cuda:0')\n",
      "val loss: 3.0751177307128907\n",
      "val acc: tensor(0.2461, device='cuda:0')\n",
      "running loss: 2.826460838317871\n",
      "running loss: 2.8660793152219077\n",
      "training acc: tensor(0.2896, device='cuda:0')\n",
      "val loss: 2.9953153076171875\n",
      "val acc: tensor(0.2717, device='cuda:0')\n",
      "running loss: 2.6801528930664062\n",
      "running loss: 2.6513407267035847\n",
      "training acc: tensor(0.3300, device='cuda:0')\n",
      "val loss: 2.9211225814819337\n",
      "val acc: tensor(0.2856, device='cuda:0')\n",
      "running loss: 2.5300540924072266\n",
      "running loss: 2.4838357409664646\n",
      "training acc: tensor(0.3676, device='cuda:0')\n",
      "val loss: 2.8412870708465574\n",
      "val acc: tensor(0.3043, device='cuda:0')\n",
      "running loss: 2.219971179962158\n",
      "running loss: 2.2874689544765303\n",
      "training acc: tensor(0.4037, device='cuda:0')\n",
      "val loss: 2.820470008468628\n",
      "val acc: tensor(0.3131, device='cuda:0')\n",
      "running loss: 2.0860486030578613\n",
      "running loss: 2.148494275434458\n",
      "training acc: tensor(0.4389, device='cuda:0')\n",
      "val loss: 2.791726114273071\n",
      "val acc: tensor(0.3165, device='cuda:0')\n",
      "running loss: 2.073124885559082\n",
      "running loss: 2.0256556519778224\n",
      "training acc: tensor(0.4737, device='cuda:0')\n",
      "val loss: 2.8028280906677248\n",
      "val acc: tensor(0.3218, device='cuda:0')\n",
      "running loss: 1.6339504718780518\n",
      "running loss: 1.8285616540424705\n",
      "training acc: tensor(0.5079, device='cuda:0')\n",
      "val loss: 2.8197302513122557\n",
      "val acc: tensor(0.3302, device='cuda:0')\n",
      "running loss: 1.6893575191497803\n",
      "running loss: 1.7475827112841893\n",
      "training acc: tensor(0.5364, device='cuda:0')\n",
      "val loss: 2.841245450592041\n",
      "val acc: tensor(0.3285, device='cuda:0')\n",
      "running loss: 1.7603890895843506\n",
      "running loss: 1.656255836356876\n",
      "training acc: tensor(0.5651, device='cuda:0')\n",
      "val loss: 2.860155464553833\n",
      "val acc: tensor(0.3251, device='cuda:0')\n",
      "running loss: 1.5766180753707886\n",
      "running loss: 1.536767051867709\n",
      "training acc: tensor(0.5909, device='cuda:0')\n",
      "val loss: 2.8839251487731934\n",
      "val acc: tensor(0.3262, device='cuda:0')\n",
      "running loss: 1.3664071559906006\n",
      "running loss: 1.4452572429125459\n",
      "training acc: tensor(0.6158, device='cuda:0')\n",
      "val loss: 2.900116205215454\n",
      "val acc: tensor(0.3290, device='cuda:0')\n",
      "running loss: 1.1620690822601318\n",
      "running loss: 1.339078660915553\n",
      "training acc: tensor(0.6364, device='cuda:0')\n",
      "val loss: 2.9283958206176757\n",
      "val acc: tensor(0.3242, device='cuda:0')\n",
      "running loss: 1.3334131240844727\n",
      "running loss: 1.3027958562760205\n",
      "training acc: tensor(0.6563, device='cuda:0')\n",
      "val loss: 2.9714962310791018\n",
      "val acc: tensor(0.3235, device='cuda:0')\n",
      "running loss: 1.164146900177002\n",
      "running loss: 1.2199197057144096\n",
      "training acc: tensor(0.6730, device='cuda:0')\n",
      "val loss: 2.9633226272583006\n",
      "val acc: tensor(0.3330, device='cuda:0')\n",
      "running loss: 0.8230723738670349\n",
      "running loss: 1.1304996911228258\n",
      "training acc: tensor(0.6902, device='cuda:0')\n",
      "val loss: 3.0278172271728514\n",
      "val acc: tensor(0.3216, device='cuda:0')\n",
      "running loss: 0.9281737208366394\n",
      "running loss: 1.0922356941825864\n",
      "training acc: tensor(0.7053, device='cuda:0')\n",
      "val loss: 3.0404613746643068\n",
      "val acc: tensor(0.3259, device='cuda:0')\n",
      "running loss: 1.1272776126861572\n",
      "running loss: 1.071292590916294\n",
      "training acc: tensor(0.7180, device='cuda:0')\n",
      "val loss: 3.0554448616027834\n",
      "val acc: tensor(0.3275, device='cuda:0')\n",
      "running loss: 1.1358745098114014\n",
      "running loss: 1.0498118981310463\n",
      "training acc: tensor(0.7339, device='cuda:0')\n",
      "val loss: 3.0935250228881834\n",
      "val acc: tensor(0.3206, device='cuda:0')\n",
      "running loss: 0.9147944450378418\n",
      "running loss: 0.9787288431800362\n",
      "training acc: tensor(0.7427, device='cuda:0')\n",
      "val loss: 3.1364122283935547\n",
      "val acc: tensor(0.3215, device='cuda:0')\n",
      "running loss: 0.7555004954338074\n",
      "running loss: 0.9283059978740327\n",
      "training acc: tensor(0.7528, device='cuda:0')\n",
      "val loss: 3.1424073554992678\n",
      "val acc: tensor(0.3251, device='cuda:0')\n",
      "running loss: 1.009255051612854\n",
      "running loss: 0.9233061844336687\n",
      "training acc: tensor(0.7616, device='cuda:0')\n",
      "val loss: 3.1618131614685057\n",
      "val acc: tensor(0.3224, device='cuda:0')\n",
      "running loss: 0.8565903902053833\n",
      "running loss: 0.8924968146419503\n",
      "training acc: tensor(0.7654, device='cuda:0')\n",
      "val loss: 3.140016396713257\n",
      "val acc: tensor(0.3261, device='cuda:0')\n",
      "running loss: 0.9699981808662415\n",
      "running loss: 0.8700866287111525\n",
      "training acc: tensor(0.7788, device='cuda:0')\n",
      "val loss: 3.2091494667053224\n",
      "val acc: tensor(0.3180, device='cuda:0')\n",
      "running loss: 0.7845500707626343\n",
      "running loss: 0.8354263467649247\n",
      "training acc: tensor(0.7845, device='cuda:0')\n",
      "val loss: 3.2083783126831054\n",
      "val acc: tensor(0.3180, device='cuda:0')\n",
      "running loss: 0.6693665385246277\n",
      "running loss: 0.7931263862378715\n",
      "training acc: tensor(0.7959, device='cuda:0')\n",
      "val loss: 3.2263058227539063\n",
      "val acc: tensor(0.3252, device='cuda:0')\n",
      "running loss: 0.5433540344238281\n",
      "running loss: 0.7615690525863217\n",
      "training acc: tensor(0.7986, device='cuda:0')\n",
      "val loss: 3.2423099685668944\n",
      "val acc: tensor(0.3234, device='cuda:0')\n",
      "running loss: 0.6961206793785095\n",
      "running loss: 0.7563093303456543\n",
      "training acc: tensor(0.8041, device='cuda:0')\n",
      "val loss: 3.203556690979004\n",
      "val acc: tensor(0.3292, device='cuda:0')\n",
      "running loss: 0.6050814390182495\n",
      "running loss: 0.7381073000143009\n",
      "training acc: tensor(0.8077, device='cuda:0')\n",
      "val loss: 3.27247001914978\n",
      "val acc: tensor(0.3273, device='cuda:0')\n",
      "running loss: 0.5728440880775452\n",
      "running loss: 0.712446357791054\n",
      "training acc: tensor(0.8135, device='cuda:0')\n",
      "val loss: 3.2785414699554445\n",
      "val acc: tensor(0.3254, device='cuda:0')\n",
      "running loss: 0.7892581224441528\n",
      "running loss: 0.7253072891365167\n",
      "training acc: tensor(0.8215, device='cuda:0')\n",
      "val loss: 3.298513274383545\n",
      "val acc: tensor(0.3245, device='cuda:0')\n",
      "running loss: 0.5770699381828308\n",
      "running loss: 0.6823438122932521\n",
      "training acc: tensor(0.8244, device='cuda:0')\n",
      "val loss: 3.2703079666137693\n",
      "val acc: tensor(0.3384, device='cuda:0')\n",
      "running loss: 0.5383042693138123\n",
      "running loss: 0.6655638183366948\n",
      "training acc: tensor(0.8286, device='cuda:0')\n",
      "val loss: 3.259018251800537\n",
      "val acc: tensor(0.3327, device='cuda:0')\n",
      "running loss: 0.6440339088439941\n",
      "running loss: 0.6721548848435482\n",
      "training acc: tensor(0.8330, device='cuda:0')\n",
      "val loss: 3.29025043258667\n",
      "val acc: tensor(0.3354, device='cuda:0')\n",
      "running loss: 0.6513421535491943\n",
      "running loss: 0.6419383968215628\n",
      "training acc: tensor(0.8388, device='cuda:0')\n",
      "val loss: 3.339186408996582\n",
      "val acc: tensor(0.3219, device='cuda:0')\n",
      "running loss: 0.4933798313140869\n",
      "running loss: 0.6230753137692744\n",
      "training acc: tensor(0.8411, device='cuda:0')\n",
      "val loss: 3.35381107711792\n",
      "val acc: tensor(0.3189, device='cuda:0')\n",
      "running loss: 0.5535956621170044\n",
      "running loss: 0.6242939710632691\n",
      "training acc: tensor(0.8421, device='cuda:0')\n",
      "val loss: 3.375553686904907\n",
      "val acc: tensor(0.3224, device='cuda:0')\n",
      "running loss: 0.4716341495513916\n",
      "running loss: 0.597856013874297\n",
      "training acc: tensor(0.8484, device='cuda:0')\n",
      "val loss: 3.3801890995025636\n",
      "val acc: tensor(0.3243, device='cuda:0')\n",
      "running loss: 0.40898066759109497\n",
      "running loss: 0.579367174958405\n",
      "training acc: tensor(0.8508, device='cuda:0')\n",
      "val loss: 3.352279925918579\n",
      "val acc: tensor(0.3304, device='cuda:0')\n",
      "running loss: 0.3455960154533386\n",
      "running loss: 0.5485097766991426\n",
      "training acc: tensor(0.8561, device='cuda:0')\n",
      "val loss: 3.3916038398742674\n",
      "val acc: tensor(0.3287, device='cuda:0')\n",
      "running loss: 0.4763404130935669\n",
      "running loss: 0.5732999964057952\n",
      "training acc: tensor(0.8581, device='cuda:0')\n",
      "val loss: 3.4226562187194824\n",
      "val acc: tensor(0.3241, device='cuda:0')\n",
      "running loss: 0.5059726238250732\n",
      "running loss: 0.5613960171810677\n",
      "training acc: tensor(0.8605, device='cuda:0')\n",
      "val loss: 3.3670623901367187\n",
      "val acc: tensor(0.3296, device='cuda:0')\n",
      "running loss: 0.6311657428741455\n",
      "running loss: 0.5769250062399226\n",
      "training acc: tensor(0.8619, device='cuda:0')\n",
      "val loss: 3.3957421173095703\n",
      "val acc: tensor(0.3247, device='cuda:0')\n",
      "running loss: 0.6826909780502319\n",
      "running loss: 0.5728148047836236\n",
      "training acc: tensor(0.8627, device='cuda:0')\n",
      "val loss: 3.42622307472229\n",
      "val acc: tensor(0.3240, device='cuda:0')\n",
      "running loss: 0.6090943813323975\n",
      "running loss: 0.5583708338830067\n",
      "training acc: tensor(0.8679, device='cuda:0')\n",
      "val loss: 3.4443488235473634\n",
      "val acc: tensor(0.3224, device='cuda:0')\n",
      "running loss: 0.4846819043159485\n",
      "running loss: 0.5349680191200072\n",
      "training acc: tensor(0.8668, device='cuda:0')\n",
      "val loss: 3.411824585723877\n",
      "val acc: tensor(0.3304, device='cuda:0')\n",
      "running loss: 0.4803573787212372\n",
      "running loss: 0.5319624741448759\n",
      "training acc: tensor(0.8688, device='cuda:0')\n",
      "val loss: 3.424937261962891\n",
      "val acc: tensor(0.3295, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "manifold = Lorentz(k=1.0)\n",
    "trainset = torchvision.datasets.CIFAR100(\"./cifar\", train=True, download=True, transform=torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(), \n",
    "    torchvision.transforms.Normalize((0.5074, 0.4867, 0.4411), (0.267, 0.256, 0.276))]\n",
    "    ))\n",
    "valset = torchvision.datasets.CIFAR100(\"./cifar\", train=False, download=True, transform=torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(), \n",
    "    torchvision.transforms.Normalize((0.5074, 0.4867, 0.4411), (0.267, 0.256, 0.276)),]\n",
    "    ))\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(valset, batch_size=128, shuffle=False)\n",
    "model = LorentzConvNet(input_dim=3, hidden_dim=16, num_classes=100, num_layers=5, manifold=manifold, activation=nn.ReLU()).cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "model.compile()\n",
    "data, target = next(iter(train_loader))\n",
    "for _ in range(50):\n",
    "    running_loss, acc, counts = 0.0, 0.0, 0\n",
    "    for step, (x, y) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x.cuda()).squeeze()\n",
    "        loss = F.cross_entropy(logits, y.cuda())\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        if running_loss == 0.0:\n",
    "            running_loss = loss.item()\n",
    "        else:\n",
    "            running_loss = 0.99*running_loss + 0.01*loss.item()\n",
    "        acc += (logits.argmax(dim=1) == y.cuda()).float().sum()\n",
    "        counts += x.shape[0]\n",
    "        if step % 200 == 0:\n",
    "            print(\"running loss:\", running_loss)\n",
    "    print(\"training acc:\", acc / counts)\n",
    "    with torch.no_grad():\n",
    "        running_loss, acc, counts = 0.0, 0.0, 0\n",
    "        for x, y in val_loader:\n",
    "            logits = model(x.cuda()).squeeze()\n",
    "            loss = F.cross_entropy(logits, y.cuda(), reduction='sum')\n",
    "            running_loss += loss.item()\n",
    "            acc += (logits.argmax(dim=1) == y.cuda()).float().sum()\n",
    "            counts += x.shape[0]\n",
    "        \n",
    "        print(\"val loss:\", running_loss / counts)\n",
    "        print(\"val acc:\", acc / counts)\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7b914e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running loss: 4.602324485778809\n",
      "running loss: 4.129569056731318\n",
      "training acc: tensor(0.0875, device='cuda:0')\n",
      "val loss: 3.784755062866211\n",
      "val acc: tensor(0.1259, device='cuda:0')\n",
      "running loss: 3.887423515319824\n",
      "running loss: 3.698445036380171\n",
      "training acc: tensor(0.1455, device='cuda:0')\n",
      "val loss: 3.5837403938293457\n",
      "val acc: tensor(0.1588, device='cuda:0')\n",
      "running loss: 3.560063123703003\n",
      "running loss: 3.5119678685079188\n",
      "training acc: tensor(0.1706, device='cuda:0')\n",
      "val loss: 3.518911082458496\n",
      "val acc: tensor(0.1710, device='cuda:0')\n",
      "running loss: 3.5764331817626953\n",
      "running loss: 3.463195377418665\n",
      "training acc: tensor(0.1811, device='cuda:0')\n",
      "val loss: 3.41609995803833\n",
      "val acc: tensor(0.1994, device='cuda:0')\n",
      "running loss: 3.3845832347869873\n",
      "running loss: 3.376326591840448\n",
      "training acc: tensor(0.1967, device='cuda:0')\n",
      "val loss: 3.344493743133545\n",
      "val acc: tensor(0.2101, device='cuda:0')\n",
      "running loss: 3.1745591163635254\n",
      "running loss: 3.2864272021540972\n",
      "training acc: tensor(0.2073, device='cuda:0')\n",
      "val loss: 3.306419847869873\n",
      "val acc: tensor(0.2159, device='cuda:0')\n",
      "running loss: 3.1225781440734863\n",
      "running loss: 3.2242187244246328\n",
      "training acc: tensor(0.2217, device='cuda:0')\n",
      "val loss: 3.2699598457336427\n",
      "val acc: tensor(0.2209, device='cuda:0')\n",
      "running loss: 3.069697380065918\n",
      "running loss: 3.1551700390383606\n",
      "training acc: tensor(0.2318, device='cuda:0')\n",
      "val loss: 3.207876049041748\n",
      "val acc: tensor(0.2351, device='cuda:0')\n",
      "running loss: 3.0626413822174072\n",
      "running loss: 3.1047532613404476\n",
      "training acc: tensor(0.2457, device='cuda:0')\n",
      "val loss: 3.125114176940918\n",
      "val acc: tensor(0.2502, device='cuda:0')\n",
      "running loss: 2.8953847885131836\n",
      "running loss: 3.053157468313938\n",
      "training acc: tensor(0.2547, device='cuda:0')\n",
      "val loss: 3.1383041652679444\n",
      "val acc: tensor(0.2468, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "manifold = Lorentz(k=1.0)\n",
    "trainset = torchvision.datasets.CIFAR100(\"./cifar\", train=True, download=True, transform=torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(), \n",
    "    torchvision.transforms.Normalize((0.5074, 0.4867, 0.4411), (0.267, 0.256, 0.276))]\n",
    "    ))\n",
    "valset = torchvision.datasets.CIFAR100(\"./cifar\", train=False, download=True, transform=torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(), \n",
    "    torchvision.transforms.Normalize((0.5074, 0.4867, 0.4411), (0.267, 0.256, 0.276)),]\n",
    "    ))\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(valset, batch_size=128, shuffle=False)\n",
    "model = LorentzConvNet(input_dim=3, hidden_dim=16, num_classes=100, num_layers=5, manifold=manifold, activation=nn.Identity()).cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "data, target = next(iter(train_loader))\n",
    "for _ in range(10):\n",
    "    running_loss, acc, counts = 0.0, 0.0, 0\n",
    "    for step, (x, y) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x.cuda()).squeeze()\n",
    "        loss = F.cross_entropy(logits, y.cuda())\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        if running_loss == 0.0:\n",
    "            running_loss = loss.item()\n",
    "        else:\n",
    "            running_loss = 0.99*running_loss + 0.01*loss.item()\n",
    "        acc += (logits.argmax(dim=1) == y.cuda()).float().sum()\n",
    "        counts += x.shape[0]\n",
    "        if step % 200 == 0:\n",
    "            print(\"running loss:\", running_loss)\n",
    "    print(\"training acc:\", acc / counts)\n",
    "    with torch.no_grad():\n",
    "        running_loss, acc, counts = 0.0, 0.0, 0\n",
    "        for x, y in val_loader:\n",
    "            logits = model(x.cuda()).squeeze()\n",
    "            loss = F.cross_entropy(logits, y.cuda(), reduction='sum')\n",
    "            running_loss += loss.item()\n",
    "            acc += (logits.argmax(dim=1) == y.cuda()).float().sum()\n",
    "            counts += x.shape[0]\n",
    "        \n",
    "        print(\"val loss:\", running_loss / counts)\n",
    "        print(\"val acc:\", acc / counts)\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf51f33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hyperbolic-fully-connected",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
